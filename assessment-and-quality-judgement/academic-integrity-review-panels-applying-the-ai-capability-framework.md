# Academic Integrity Review Panels: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

---

## 1. Purpose of This Scenario

This scenario supports **academic integrity review panels** where concerns about student conduct, assessment integrity, or misuse of AI are examined and adjudicated.

These panels sit at a highly sensitive intersection of:
- student trust and wellbeing
- fairness and due process
- institutional reputation
- regulatory and legal accountability

As generative AI becomes widely available, integrity panels are increasingly asked to judge cases involving **ambiguous, contested, or poorly evidenced AI use**. In many cases, uncertainty — not misconduct — is the central challenge.

The purpose of this scenario is to help panels use AI-aware reasoning that is **fair, defensible, proportionate, and human-centred**, while resisting automation, inference, or technological overreach.

This scenario is designed to support:
- Academic integrity and misconduct panels
- Chairs and secretaries of disciplinary committees
- Programme leaders and assessment leads
- Student support, welfare, and governance staff

---

## 2. Situation & Context

An academic integrity panel has been convened following a concern such as:
- suspected inappropriate AI use
- unclear authorship or process evidence
- breaches of stated assessment conditions
- inconsistencies between student work and expectations

In AI-related cases, panels often face:
- incomplete or indirect evidence
- over-reliance on detection tools
- unclear institutional guidance
- anxiety about precedent and consistency

Typical pressures include:
- safeguarding fairness to students
- avoiding both false positives and false negatives
- maintaining confidence in academic standards
- responding to external scrutiny or complaints

How AI is framed in these panels directly affects **justice, legitimacy, and trust**.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may appear in integrity panel contexts as:
- part of the original assessment process
- a detection or screening tool
- a support tool used by the student
- a summarisation or case-preparation aid for staff

These uses matter because:
- AI detection is probabilistic, not evidentiary
- outputs are often misinterpreted as proof
- summaries can obscure context and student voice
- over-confidence in tools can undermine due process

This scenario treats AI use in integrity panels as **high-risk and rights-sensitive**.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before considering evidence, panels should clarify:
- what policy actually states about AI use
- what constitutes evidence versus suspicion
- what standard of proof applies
- what uncertainty cannot be resolved

Key awareness questions:
- Are we judging conduct, process, or outcome?
- What assumptions are we making about AI capability?
- What guidance did the student reasonably rely on?
- Where is ambiguity institutional rather than individual?

AI should never be used to compensate for unclear policy.

---

### 4.2 Human–AI Co-Agency

In integrity proceedings:
- humans must retain full responsibility for judgement
- AI must never determine guilt, intent, or credibility

Good co-agency means:
- panels critically interrogate any AI-generated indicators
- student explanations are taken seriously
- judgement rests on policy, evidence, and proportionality

Avoid:
- treating AI detection scores as findings
- inferring intent from output characteristics
- allowing AI to replace deliberation

Academic judgement cannot be automated without injustice.

---

### 4.3 Applied Practice

Appropriate AI uses include:
- supporting administrative case collation
- helping panels navigate large documentation sets
- drafting neutral summaries for review (with validation)

Inappropriate uses include:
- automated classification of misconduct
- generating panel conclusions
- ranking likelihood of wrongdoing
- filtering student statements

AI should support clarity, not adjudication.

---

### 4.4 Ethics, Equity & Impact

Integrity panels have profound ethical implications.

Use the Framework to ask:
- Are certain students disproportionately scrutinised?
- Do access, language, or disability affect interpretation?
- Could AI use amplify existing inequities?
- Are we protecting student dignity and wellbeing?

Ethical integrity processes prioritise **care, fairness, and proportionality**, not deterrence through fear.

---

### 4.5 Decision-Making & Governance

Strong governance practices include:
- explicit reference to policy and evidence standards
- clear separation between suspicion and finding
- documented reasoning for outcomes
- proportional sanctions aligned to learning intent

If AI is referenced:
- explain its limitations explicitly
- record how it informed (but did not determine) judgement
- avoid creating AI-dependent precedents

Panel decisions must remain **auditable, human, and contestable**.

---

### 4.6 Reflection, Learning & Renewal

After cases conclude, institutions should reflect:
- Where did guidance fail to support clarity?
- How confident were panel members in AI literacy?
- What patterns suggest systemic issues?
- What training or policy revision is needed?

Reflection ensures integrity processes evolve with practice, not panic.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What evidence do we actually have?
- What reasonable interpretation favours the student?
- Are we responding to misconduct or uncertainty?

**Optional AI prompts**
- “Summarise the case facts without inference or judgement.”
- “List assumptions that may be influencing this discussion.”

**Pause & check**
- Would this decision feel fair if we were the student?
- Are we using AI to clarify — or to justify?

---

## 6. After-Action Reflection

Following panel decisions:
- Were outcomes clearly explained and supported?
- Did AI use increase or reduce confidence?
- Were students supported appropriately?
- What institutional learning emerged?

Use learning to strengthen policy, communication, and staff confidence.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- adjudicate AI-related integrity cases fairly and defensibly
- avoid over-reliance on detection or inference
- protect student trust and due process
- align integrity processes with educational values
- build mature, rights-aware AI capability in governance contexts
