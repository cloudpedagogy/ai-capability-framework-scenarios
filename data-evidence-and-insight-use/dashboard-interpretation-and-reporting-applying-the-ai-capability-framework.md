# Dashboard Interpretation and Reporting: Applying the AI Capability Framework

## 1. Purpose of This Scenario

This scenario supports professionals who are interpreting, discussing, or reporting on dashboards, analytics, or AI-mediated insight summaries that inform decisions, priorities, or accountability processes.

Dashboards increasingly shape what organisations *believe* about performance, risk, progress, and impact. When AI is used to aggregate data, surface patterns, generate summaries, or explain trends, it can create an appearance of objectivity and certainty — even where assumptions, proxies, or omissions materially affect interpretation.

The purpose of this scenario is to help teams use AI-supported dashboards responsibly, ensuring that interpretation, narrative construction, and reporting remain grounded in human judgement, epistemic humility, and defensible reasoning.

This scenario is designed to support:
- Senior leaders and managers
- Strategy, planning, and performance teams
- Analysts and insight professionals
- Governance and reporting committees
- Anyone responsible for explaining data to others

---

## 2. Situation & Context

A dashboard or analytics report is being reviewed, discussed, or prepared for circulation.

It may be used to:
- brief senior leadership or boards
- inform prioritisation or resource allocation
- evidence progress against strategy or KPIs
- communicate performance to regulators, partners, or the public

The dashboard may include:
- aggregated metrics and indicators
- AI-generated summaries or commentary
- trend analysis or forecasts
- benchmarks, thresholds, or risk flags

Common pressures at this stage include:
- expectations of clarity and decisiveness
- limited time for scrutiny
- reliance on headline indicators
- uneven understanding of how metrics were constructed

AI may be used to summarise patterns or highlight signals, but this is also the point where interpretation, framing, and judgement most strongly shape downstream decisions.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in dashboard interpretation and reporting to:
- generate executive summaries or narratives
- identify trends, anomalies, or correlations
- rank performance indicators or risks
- explain variance or change over time
- translate dashboards into slide decks or reports

These uses matter because:
- AI-generated narratives can smooth uncertainty into confidence
- proxy measures may be treated as outcomes
- correlations may be mistaken for explanation or causation
- missing or poor-quality data may be invisible in summaries
- framing choices can steer decision-making implicitly

This scenario treats AI use in dashboard interpretation as **medium- to high-risk**, particularly when reports inform high-stakes decisions or external accountability.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before interpreting or reporting on dashboards, teams should clarify:
- what the data actually represents
- how metrics were selected and constructed
- what is *not* being captured or measured
- where uncertainty or judgement is required

Key awareness questions:
- What decisions might this dashboard influence?
- Which indicators are proxies rather than direct measures?
- Where might AI summaries be overstating confidence?
- What assumptions are embedded in thresholds or benchmarks?

AI should be used to surface patterns — not to define reality.

---

### 4.2 Human–AI Co-Agency

In dashboard interpretation:
- humans remain responsible for meaning, judgement, and narrative
- AI may assist with organisation, pattern detection, or drafting

Good co-agency means:
- humans decide what the data *means*
- AI outputs are treated as interpretive aids, not conclusions
- multiple interpretations are considered before settling on a narrative

Avoid:
- deferring to AI-generated explanations
- treating dashboard outputs as neutral or self-evident
- allowing AI to determine “what matters” implicitly

---

### 4.3 Applied Practice

Appropriate AI uses include:
- generating alternative summaries for comparison
- highlighting anomalies or areas requiring scrutiny
- organising complex data for human review
- supporting exploratory questioning

Inappropriate uses include:
- producing a single authoritative narrative
- ranking performance without contextual discussion
- explaining causality without supporting evidence
- suppressing uncertainty for clarity

AI should support *interpretation*, not replace it.

---

### 4.4 Ethics, Equity & Impact

Dashboard narratives have ethical consequences.

Use the Framework to ask:
- Who is affected by how this data is interpreted?
- Are certain groups invisible or misrepresented in the metrics?
- Does the dashboard privilege what is easy to measure over what matters?
- Could AI-generated summaries reinforce existing power imbalances?

Ethical dashboard use requires attention to representation, fairness, and downstream impact.

---

### 4.5 Decision-Making & Governance

Good governance practices include:
- documenting interpretive assumptions
- distinguishing data from judgement explicitly
- recording how dashboards informed decisions
- clarifying limits of confidence and certainty

If AI is used:
- note its role in generating summaries or insights
- ensure human validation of narratives
- avoid opaque or unchallengeable reporting

This supports auditability, defensibility, and trust.

---

### 4.6 Reflection, Learning & Renewal

After reporting or decision-making, reflect:
- Did the dashboard meaningfully support judgement?
- Where did AI outputs help or hinder understanding?
- What uncertainties were glossed over?
- How should dashboard design or interpretation evolve?

Reflection builds organisational capability — not just better reports.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What does this data *not* tell us?
- What alternative interpretations are plausible?
- Where are we relying on proxies or assumptions?

**Optional AI prompts**
- “Generate two alternative interpretations of this dashboard, noting assumptions.”
- “Highlight indicators that may be misleading or incomplete.”

**Pause & check**
- Are we mistaking coherence for insight?
- Would we defend this interpretation if challenged?

---

## 6. After-Action Reflection

Following dashboard use:
- How did the interpretation influence decisions?
- Were any consequences unexpected?
- What data or insight gaps became visible?

Feed learning into dashboard design, data governance, and reporting practices.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- interpret AI-mediated dashboards responsibly
- avoid false certainty and narrative lock-in
- surface assumptions and limitations explicitly
- strengthen accountability in data-informed decisions
- build mature AI capability around evidence and insight
