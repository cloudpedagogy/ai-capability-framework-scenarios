# Evidence Synthesis for Decision-Making: Applying the AI Capability Framework

## 1. Purpose of This Scenario

This scenario supports situations where multiple sources of evidence must be synthesised to inform a decision. This may include research findings, evaluations, consultation feedback, performance data, policy inputs, or expert judgement.

AI is increasingly used to assist with evidence synthesis — summarising documents, clustering themes, comparing sources, or generating integrated narratives. While this can reduce cognitive load and support sensemaking, it also risks collapsing disagreement, masking uncertainty, or producing overly coherent narratives that obscure judgement and trade-offs.

The purpose of this scenario is to help professionals use AI to support evidence synthesis responsibly, while ensuring that interpretation, weighting, and decision ownership remain explicitly human.

This scenario is designed to support:
- Senior leaders and decision-makers
- Policy, strategy, and planning teams
- Research managers and evaluators
- Governance committees and boards
- Anyone responsible for integrating evidence into decisions

---

## 2. Situation & Context

A decision must be made that depends on multiple forms of evidence.

Examples include:
- approving or revising a programme, policy, or strategy
- responding to an external review or evaluation
- prioritising investment or resource allocation
- determining whether evidence is “sufficient” to act

The evidence base may include:
- reports, evaluations, or research papers
- quantitative indicators and dashboards
- qualitative feedback or consultation responses
- expert opinion or professional judgement

Common pressures at this stage include:
- volume and complexity of materials
- time constraints and decision deadlines
- desire for a single, clear narrative
- uneven familiarity with evidence across participants

AI may be proposed to synthesise evidence quickly — but this is also where interpretive risk is highest.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in evidence synthesis to:
- summarise large sets of documents
- identify themes or areas of convergence
- compare findings across sources
- generate integrated briefing papers
- highlight perceived strengths or gaps

These uses matter because:
- synthesis can flatten disagreement or minority views
- weighting of evidence may be implicit rather than explicit
- AI-generated narratives can appear neutral but embed assumptions
- uncertainty may be reduced to confidence through language

This scenario treats AI use in evidence synthesis as **high epistemic risk**, requiring careful governance and facilitation.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before synthesising evidence, clarify:
- what decision the synthesis is meant to inform
- what types of evidence are being considered
- what counts as strong, weak, or contested evidence
- where professional judgement is unavoidable

Key awareness questions:
- Are we seeking understanding or justification?
- What disagreements or tensions exist in the evidence?
- Where might AI outputs imply consensus prematurely?
- What evidence is missing or under-represented?

AI should be used to *surface structure*, not to decide meaning.

---

### 4.2 Human–AI Co-Agency

In evidence synthesis:
- humans remain responsible for interpretation and weighting
- AI may assist with organisation and comparison

Good co-agency means:
- humans define synthesis questions and criteria
- AI outputs are reviewed, challenged, and contextualised
- decisions about relevance and sufficiency remain human

Avoid:
- allowing AI to determine which evidence “matters”
- treating synthesis as neutral aggregation
- outsourcing judgement to automated summaries

---

### 4.3 Applied Practice

Appropriate AI uses include:
- producing parallel summaries for comparison
- highlighting areas of agreement and disagreement
- organising evidence by question or criterion
- supporting exploratory sensemaking

Inappropriate uses include:
- producing a single authoritative synthesis
- resolving contradictions through summarisation
- ranking evidence sources implicitly
- masking uncertainty to support decisiveness

AI should support *deliberation*, not closure.

---

### 4.4 Ethics, Equity & Impact

Evidence synthesis shapes whose knowledge counts.

Use the Framework to ask:
- Which voices or perspectives are privileged?
- Are certain forms of evidence over-weighted?
- Could AI synthesis marginalise lived experience or minority views?
- How might this synthesis affect trust or legitimacy?

Ethical synthesis requires transparency, plurality, and care.

---

### 4.5 Decision-Making & Governance

Good governance practices include:
- documenting synthesis criteria and assumptions
- distinguishing evidence from interpretation explicitly
- recording dissent or uncertainty where present
- clarifying how synthesis informed the final decision

If AI is used:
- document its role and limitations
- avoid retaining AI-generated synthesis as sole decision artefacts
- ensure human sign-off on interpretive narratives

This supports defensibility and accountability.

---

### 4.6 Reflection, Learning & Renewal

After decisions are made, reflect:
- Did synthesis clarify or oversimplify?
- Where did AI help or hinder judgement?
- What evidence gaps became visible?
- How could synthesis practices improve next time?

Reflection strengthens organisational evidence capability over time.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What evidence are we trusting most — and why?
- What tensions are being smoothed over?
- Where does judgement, not evidence, drive the decision?

**Optional AI prompts**
- “Summarise areas of disagreement across these sources without resolving them.”
- “Identify assumptions implicit in this synthesis.”

**Pause & check**
- Are we mistaking synthesis for certainty?
- Would this synthesis stand up to scrutiny?

---

## 6. After-Action Reflection

Following evidence-informed decisions:
- How did synthesis shape confidence and consensus?
- Were any consequences unexpected?
- What learning should inform future evidence use?

Feed insights into guidance, training, and governance processes.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- synthesise evidence responsibly using AI
- avoid false consensus and narrative overreach
- surface assumptions and judgement explicitly
- strengthen legitimacy in evidence-based decisions
- build mature AI capability around knowledge integration
