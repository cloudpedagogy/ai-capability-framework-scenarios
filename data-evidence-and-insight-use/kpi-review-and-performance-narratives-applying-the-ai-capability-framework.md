# KPI Review and Performance Narratives: Applying the AI Capability Framework

## 1. Purpose of This Scenario

This scenario supports situations where key performance indicators (KPIs) and performance data are reviewed, interpreted, and translated into narratives for leadership, governance, or external reporting.

AI is increasingly used to analyse KPI data, generate summaries, explain trends, or draft performance narratives. While these tools can improve efficiency and consistency, they also risk overstating significance, masking uncertainty, or converting proxy metrics into claims about quality, impact, or effectiveness.

The purpose of this scenario is to help professionals use AI to support responsible interpretation of KPIs, while ensuring that performance narratives remain grounded in human judgement, contextual understanding, and ethical accountability.

This scenario is designed to support:
- Senior leaders and management teams
- Strategy, planning, and performance units
- Governance committees and boards
- Quality assurance and evaluation teams
- Communications and reporting professionals

---

## 2. Situation & Context

A KPI review or performance discussion is taking place. This may be part of:
- routine performance reporting cycles
- strategic reviews or board reporting
- external accountability or regulatory submissions
- internal improvement or risk conversations

Data may include:
- dashboards and scorecards
- trend analyses over time
- benchmarks or league-table comparisons
- targets and thresholds

Common pressures include:
- expectation of clear explanations and direction
- reputational or accountability risk
- incentives to demonstrate improvement
- limited time to interrogate underlying data quality

AI may be proposed to help “make sense” of the numbers — but this is where narrative risk emerges.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in KPI review to:
- summarise performance trends
- explain changes or anomalies
- draft narrative commentary for reports
- benchmark performance against peers
- highlight areas of concern or success

These uses matter because:
- AI explanations may imply causality where none is proven
- narratives can reframe proxy indicators as outcomes
- benchmarking may import inappropriate comparisons
- confident language can obscure data limitations

This scenario treats AI use in KPI interpretation as **medium- to high-risk**, particularly where decisions, reputations, or accountability are at stake.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI in KPI review, clarify:
- what each KPI is actually measuring (and not measuring)
- the assumptions embedded in targets and thresholds
- known data quality or coverage issues
- what decisions the KPI review is meant to inform

Key awareness questions:
- Are these indicators proxies or outcomes?
- What uncertainty or noise exists in the data?
- Where might AI-generated narratives overstate meaning?
- What contextual factors are not visible in the metrics?

AI should be used to *support questioning*, not to finalise interpretation.

---

### 4.2 Human–AI Co-Agency

In KPI review:
- humans remain responsible for interpretation and judgement
- AI may assist with pattern detection or summarisation

Good co-agency means:
- humans define the questions being asked of the data
- AI outputs are treated as prompts for discussion
- final narratives are explicitly human-authored

Avoid:
- allowing AI to “explain” performance without challenge
- treating AI narratives as neutral or objective
- delegating accountability for interpretation to tools

---

### 4.3 Applied Practice

Appropriate AI uses include:
- generating alternative explanations for trends
- identifying areas requiring deeper investigation
- drafting neutral descriptive summaries for review
- surfacing inconsistencies across indicators

Inappropriate uses include:
- asserting causes or impacts without evidence
- ranking performance without contextual analysis
- producing polished narratives without scrutiny
- converting targets into value judgements automatically

AI should support *interpretation*, not performance storytelling.

---

### 4.4 Ethics, Equity & Impact

KPI narratives influence behaviour and resource allocation.

Use the Framework to ask:
- Who is advantaged or disadvantaged by these indicators?
- Do KPIs reflect what actually matters?
- Could AI narratives reinforce perverse incentives?
- Are certain impacts or groups invisible in the data?

Ethical performance review requires resisting metric dominance and acknowledging limits.

---

### 4.5 Decision-Making & Governance

Strong governance practices include:
- clear documentation of KPI definitions and limitations
- separation of data description from judgement
- transparency about how narratives were developed
- appropriate escalation where indicators are contested

If AI is used:
- record its role in analysis or drafting
- ensure narratives are reviewed and approved by accountable leaders
- avoid treating AI-generated text as formal assurance

This supports credibility, auditability, and trust.

---

### 4.6 Reflection, Learning & Renewal

After KPI reviews, reflect:
- Did AI use clarify or distort understanding?
- Where did narratives feel overconfident or vague?
- What indicators need revision or supplementation?
- How can KPI use better support learning rather than control?

Reflection helps organisations mature their relationship with metrics and AI.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What does this KPI not tell us?
- Where are we inferring more than the data supports?
- How might this narrative influence behaviour?

**Optional AI prompts**
- “Generate alternative explanations for this trend, noting uncertainty.”
- “Identify limitations or caveats associated with these KPIs.”

**Pause & check**
- Are we mistaking measurement for meaning?
- Would we defend this narrative under scrutiny?

---

## 6. After-Action Reflection

Following performance reporting:
- How were narratives received and interpreted?
- Did decisions align with what the data could genuinely support?
- What unintended consequences emerged?

Use insights to refine indicators, narratives, and AI use over time.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- interpret KPIs responsibly using AI
- avoid narrative overreach and metric fixation
- surface assumptions and limitations explicitly
- strengthen governance around performance reporting
- build mature AI capability in performance and accountability contexts
