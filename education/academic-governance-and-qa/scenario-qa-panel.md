# Scenario 1: QA Panel Scrutiny of AI-Supported Practice

## Scenario Context

During a validation or revalidation event, a panel member asks:

> “How can the institution assure us that academic standards are being maintained when AI tools are used by students and staff?”

This question reflects increasing sector concern about governance, not technology.

---

## Task

Prepare a response that demonstrates:
- structured decision-making
- explicit design choices
- governance rather than reliance on trust
- alignment with institutional standards

---

## Weak Response (Avoid)

> “We trust staff and students to use AI responsibly.”

This response lacks:
- process
- documentation
- assurance
- evidence

---

## Strong, Defensible Response (Example)

> “AI use is treated as a designed condition of learning and assessment. Learning outcomes, assessment criteria, and guidance explicitly locate academic judgement with the learner and assessor. Decisions about AI use are documented using a structured capability framework and reviewed as part of our quality assurance processes. This ensures consistency, transparency, and defensibility.”

---

## Likely Follow-Up Questions

- How is this communicated to students and staff?
- How is marker consistency ensured?
- How are risks identified and reviewed?
- How does the institution adapt as tools evolve?

---

## Capability Focus

Primary: **Decision-Making & Governance**  
Supporting: Awareness, Human–AI Co-Agency, Reflection & Renewal

---

## Outcome

Participants should be able to articulate:
- how AI-related decisions are governed
- how standards are protected
- how assurance is demonstrated, not assumed
