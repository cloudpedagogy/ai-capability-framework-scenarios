# Scenario 2: Marker Consistency in AI-Supported Assessment

## Scenario Context

Markers report uncertainty about how to interpret student work where AI may have been used. Some markers penalise perceived AI use; others ignore it entirely.

This results in:
- inconsistent marking
- student complaints
- QA risk

---

## Task

Examine how assessment criteria and guidance contribute to marker inconsistency.

---

## Key Questions

- Do marking criteria explicitly reference judgement and decision-making?
- Are expectations around AI use stated or assumed?
- Are markers being asked to infer AI use rather than assess learning?

---

## Design Adjustment

Revise assessment guidance so that:
- markers assess evidence of judgement, not authorship
- AI use is evaluated through transparency and explanation
- criteria focus on reasoning, justification, and evaluation

---

## QA and Fairness Considerations

From a QA perspective:
- consistency is a core integrity requirement
- reliance on individual marker interpretation creates risk
- explicit criteria reduce bias and variability

---

## Outcome

A shared marking framework that:
- supports parity of student experience
- reduces informal judgement calls
- aligns marker practice with assessment design
