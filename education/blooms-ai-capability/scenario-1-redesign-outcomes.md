# Scenario 1: Retrofitting Learning Outcomes for AI-Aware Practice

## Scenario Context

You are part of a programme team reviewing learning outcomes for a course that is already using generative AI in practice — even if not formally acknowledged.

Students are:
- drafting text with AI
- using AI for ideation and structuring
- checking clarity, tone, or synthesis

However, the published learning outcomes make no reference to AI, judgement, or responsibility. This creates misalignment between:
- what students actually do
- what the course claims to assess
- what the institution can defend if challenged

Your task is to retrofit outcomes using Bloom’s Taxonomy **and** the AI Capability Framework.

---

## Starting Point (Existing Outcome)

> “Critically evaluate contemporary policy literature in the field.”

---

## Task

Redesign this outcome so that it:
1. Retains a clear Bloom-level cognitive demand
2. Explicitly acknowledges AI use
3. Makes expectations around judgement, ethics, and governance visible

---

## Dual-Axis Redesign Example

**Revised Learning Outcome**

> “Critically evaluate contemporary policy literature, using generative AI tools to support synthesis and comparison, while demonstrating informed judgement, transparency of method, and ethical awareness in line with institutional AI guidance.”

---

## Capability Reflection Prompts (Facilitated)

Ask the team:

- **Domain 1 – Awareness:**  
  What assumptions are we making about students’ AI literacy?

- **Domain 2 – Human–AI Co-Agency:**  
  Where does judgement sit — with the learner or the tool?

- **Domain 3 – Applied Practice:**  
  What AI uses are encouraged, optional, or discouraged?

- **Domain 4 – Ethics, Equity & Impact:**  
  Who might be advantaged or disadvantaged by this design?

- **Domain 5 – Decision-Making & Governance:**  
  Could we justify this outcome to an external examiner?

- **Domain 6 – Reflection & Renewal:**  
  How will we revisit this outcome as tools change?

---

## Output

A revised set of learning outcomes that:
- still read naturally within programme documentation
- surface AI use without over-specifying tools
- shift AI from “hidden practice” to “designed capability”
