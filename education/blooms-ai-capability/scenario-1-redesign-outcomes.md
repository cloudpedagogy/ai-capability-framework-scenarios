# Scenario 1: Redesigning Learning Outcomes for AI-Aware Practice

## Scenario Context

A programme team is reviewing learning outcomes for a course in which students are already using generative AI tools for:

- drafting and structuring work
- summarising or comparing sources
- generating ideas or alternative perspectives

However, existing learning outcomes make no reference to AI use, judgement, or responsibility. This creates misalignment between:

- actual learning practice
- assessment expectations
- what the institution can defend during QA or accreditation review

---

## Existing Learning Outcome

> “Critically evaluate contemporary policy literature in the field.”

This outcome is cognitively clear, but silent on the conditions under which evaluation takes place.

---

## Task

Redesign the outcome so that it:

1. Retains a clear Bloom-level cognitive demand  
2. Explicitly acknowledges AI use where relevant  
3. Makes expectations around judgement, ethics, and accountability visible  
4. Remains defensible under UK QA scrutiny  

---

## Revised Learning Outcome (Example)

> “Critically evaluate contemporary policy literature, using generative AI tools to support synthesis and comparison where appropriate, while demonstrating independent judgement, transparency of method, and ethical awareness in line with institutional AI guidance.”

---

## QA and Standards Considerations

From a UK QA perspective, consider:

- Is the level of cognitive demand unchanged?
- Is AI use explicit enough to avoid ambiguity for students and markers?
- Is responsibility clearly located with the learner?
- Could this outcome be justified to an external examiner or PSRB panel?

This approach supports QAA expectations that learning outcomes are:

- clearly articulated
- aligned with assessment
- reflective of current educational practice
- capable of being reviewed and assured

---

## AI Capability Reflection Prompts

Use these prompts to support structured discussion:

- **Domain 1 – Awareness:**  
  What AI knowledge are we assuming students already have?

- **Domain 2 – Human–AI Co-Agency:**  
  Where must human judgement be visible?

- **Domain 3 – Applied Practice:**  
  Which AI uses are permitted, bounded, or discouraged?

- **Domain 4 – Ethics, Equity & Impact:**  
  Are there equity or bias considerations in this design?

- **Domain 5 – Decision-Making & Governance:**  
  How would we evidence this design decision if challenged?

- **Domain 6 – Reflection & Renewal:**  
  How will this outcome be reviewed as AI tools evolve?

---

## Output

A revised set of learning outcomes that:

- remain readable within programme documentation
- align with assessment practices
- make AI use explicit and governable
- support defensible academic standards
