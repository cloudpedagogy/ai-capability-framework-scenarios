# Scenario 3: QA and PSRB Panel Challenge

## Scenario Context

During validation, revalidation, or PSRB accreditation, a panel member asks:

> “How can you assure us that students are exercising independent academic judgement when AI tools are involved?”

This scenario simulates that line of questioning.

---

## Task

Prepare a response that demonstrates:

- clarity of learning outcomes
- integrity of assessment design
- governance of AI use
- defensibility of academic standards

---

## Weak Response (Avoid)

> “We trust students to use AI responsibly.”

This response lacks evidence, process, and assurance.

---

## Strong, Defensible Response (Example)

> “Our learning outcomes continue to assess higher-order cognitive skills such as evaluation and synthesis. AI use is explicitly designed into the assessment conditions, and students are required to demonstrate how judgement was exercised, where AI outputs were challenged or limited, and how ethical considerations were addressed. These expectations are embedded in our rubrics and communicated clearly to students and markers.”

---

## Typical Panel Follow-Ups

- How is this communicated to students?
- How are markers supported and calibrated?
- How is consistency monitored?
- How will this approach adapt as AI tools evolve?

---

## QA Framing

Panels are not asking whether AI is used, but whether:

- academic standards are maintained
- judgement is assessed
- governance is explicit

The AI Capability Framework provides a structured vocabulary for answering these questions.

---

## Capability Focus

Primary: **Domain 5 – Decision-Making & Governance**  
Supporting: Domains 2, 3, and 6
