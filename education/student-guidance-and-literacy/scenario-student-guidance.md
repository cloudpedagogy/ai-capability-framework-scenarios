# Scenario: Designing Clear and Defensible Student Guidance on AI Use

## Scenario Context

Students report confusion about AI use across their programme:

- some modules encourage AI use
- others are silent
- expectations differ between tutors
- guidance is often informal or contradictory

As a result:
- students make assumptions
- some conceal AI use out of fear
- others unknowingly breach expectations

This creates risk for students and the institution.

---

## Task

Review existing student-facing guidance and identify where ambiguity exists.

---

## Key Questions

- What assumptions are students currently making about AI use?
- Are expectations explicit or implied?
- Do students understand where judgement and responsibility sit?
- Could guidance be interpreted differently across modules?

---

## Design Reframing

Rather than listing rules, consider framing guidance around:

- purpose (why AI may or may not be used)
- responsibility (who remains accountable)
- transparency (what should be disclosed)
- judgement (what students are expected to demonstrate)

---

## QA and Fairness Perspective

From a QA standpoint:
- unclear guidance undermines fairness
- inconsistency increases complaint risk
- hidden practice weakens assurance

Clear, institutionally mediated guidance:
- supports parity of experience
- reduces anxiety
- strengthens defensibility

---

## Outcome

A clearer articulation of student expectations that:
- aligns with assessment design
- supports responsible practice
- can be defended under QA scrutiny
