# Ethics and Approval Panels — Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

---

## 1. Purpose of This Scenario

This scenario supports ethics and approval panels where proposals, activities, or systems are reviewed for ethical acceptability, compliance, and risk. Such panels may include research ethics committees, data governance boards, programme approval panels, procurement approvals, or AI oversight groups.

Ethics and approval panels operate at the intersection of values, evidence, and authority. AI may be introduced to summarise submissions, identify risks, benchmark decisions, or check compliance. While these uses can support efficiency, they also risk narrowing ethical judgement, obscuring responsibility, or standardising decisions that require contextual sensitivity.

The purpose of this scenario is to help panel members use AI, if at all, as a bounded support for ethical deliberation, while preserving human judgement, transparency, and legitimacy.

This scenario is designed to support:

- Ethics committee and approval panel members  
- Panel chairs and secretariats  
- Governance and compliance leads  
- Academic and professional services staff supporting approval processes  

---

## 2. Situation and Context

An ethics or approval panel is convened to review one or more submissions. These may involve:

- research involving human participants or sensitive data  
- deployment of AI or data-driven systems  
- programmes or initiatives with potential societal impact  
- exceptions to policy or established norms  

Panel members typically work under constraints such as:

- large volumes of documentation  
- limited time per submission  
- diverse disciplinary and professional perspectives  

AI may be proposed to assist with reviewing materials or identifying issues. How it is used will shape the credibility, fairness, and defensibility of panel decisions.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in ethics and approval panels to:

- summarise submissions or protocols  
- flag potential ethical or compliance risks  
- compare proposals against guidelines or precedents  
- support consistency across decisions  

These uses matter because:

- summaries can omit ethically significant nuance  
- risk flags may be treated as exhaustive  
- precedent-based reasoning can flatten contextual judgement  

This scenario treats AI use in ethics and approval panels as **high-risk and legitimacy-sensitive**, requiring strict boundaries and explicit governance.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI, panels should clarify:

- the ethical principles and standards guiding review  
- the scope of the panel’s authority  
- what constitutes acceptable evidence or justification  

Key awareness questions:

- What ethical values are at stake in this decision?  
- Where is contextual judgement essential?  
- What risks might AI obscure rather than reveal?  

AI should be used to support deliberation, not to define ethical acceptability.

---

### 4.2 Human–AI Co-Agency

In ethics and approval contexts:

- humans must remain the ethical decision-makers  
- AI may assist with organisation or comparison  

Good co-agency means:

- panel members define review criteria  
- AI outputs are explicitly interrogated  
- final judgements are clearly human-authored  

Avoid:

- treating AI-generated risk assessments as decisive  
- delegating ethical interpretation to tools  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- organising submissions against review criteria  
- highlighting areas requiring deeper discussion  
- identifying inconsistencies in documentation  

Inappropriate uses include:

- making approval recommendations  
- scoring ethical acceptability  
- automating approval or rejection  

AI should remain a supporting lens, not an arbiter.

---

### 4.4 Ethics, Equity and Impact

This stage explicitly centres ethics.

Use the Framework to ask:

- Who may be affected by approval or rejection?  
- Are certain harms or benefits being undervalued?  
- Does AI use reinforce dominant norms or exclusions?  

Ethical review requires attention to power, vulnerability, and lived experience, not just compliance.

---

### 4.5 Decision-Making and Governance

Strong governance practices include:

- clear documentation of ethical reasoning  
- transparency about conditions or limitations of approval  
- separation of analysis from decision authority  

If AI is used:

- document its role and limitations  
- ensure human validation of summaries  
- avoid creating opaque decision trails  

This maintains trust in ethical oversight.

---

### 4.6 Reflection, Learning and Renewal

After panel decisions, reflect:

- Did AI use enhance or constrain ethical discussion?  
- Were any perspectives marginalised?  
- How can review processes be improved?  

Reflection strengthens ethical maturity and legitimacy over time.

---

## 5. In-the-Moment Prompts and Checks

### Human reflection prompts

- What ethical concern troubles us most here?  
- Where are we relying on precedent instead of judgement?  
- What voices or experiences are missing?  

### Optional AI prompts

- “Summarise ethical considerations raised in this submission while noting areas of uncertainty.”  
- “Identify sections of the proposal that require further ethical clarification.”  

### Pause and check

- Are we using AI to inform, not replace, ethical judgement?  
- Would we stand by this decision without reference to AI outputs?

---

## 6. After-Action Reflection

Following panel meetings, consider:

- Were decisions and conditions clearly justified?  
- Did AI use improve clarity or create false confidence?  
- What changes are needed in future review processes?  

Capture learning to strengthen ethical governance.

---

## 7. What This Scenario Delivers

This scenario helps organisations to:

- conduct more robust and legitimate ethical reviews  
- avoid over-reliance on AI in value-laden decisions  
- strengthen transparency and accountability  
- integrate equity and impact into approval processes  
- build mature, human-centred AI capability in governance contexts
