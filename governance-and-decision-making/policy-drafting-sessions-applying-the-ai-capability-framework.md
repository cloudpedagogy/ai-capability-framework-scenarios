# Policy Drafting Sessions — Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

---

## 1. Purpose of This Scenario

This scenario supports collaborative policy drafting sessions where organisational rules, guidance, or standards are developed, revised, or clarified. These sessions often involve balancing legal requirements, ethical values, operational realities, and diverse stakeholder perspectives.

AI is frequently introduced into policy drafting to accelerate writing, harmonise language, or benchmark against external policies. While these uses can improve efficiency and consistency, they also risk importing external norms uncritically, flattening debate, or masking value judgements behind apparently neutral language.

The purpose of this scenario is to help professionals use AI as a drafting and sensemaking aid, while ensuring that policy intent, accountability, and value judgements remain explicitly human.

This scenario is designed to support:

- Policy authors and owners  
- Governance and compliance teams  
- Legal and risk advisors  
- Academic and professional services staff involved in policy development  

---

## 2. Situation and Context

A policy drafting session is convened to:

- create a new policy or guideline  
- update an existing policy in response to change  
- clarify ambiguous or contested areas  

Participants may include:

- subject matter experts  
- operational leads  
- governance or legal representatives  

Common pressures include:

- tight timelines  
- competing priorities or interpretations  
- pressure for alignment with sector norms  

AI may be proposed to help draft text, reconcile versions, or scan external examples. How it is used will influence whose values and assumptions shape the final policy.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in policy drafting to:

- generate initial draft language  
- summarise consultation feedback  
- compare internal drafts with external policies  
- standardise terminology  

These uses matter because:

- generated text can obscure contested choices  
- benchmarking may import inappropriate norms  
- standardisation can suppress local nuance  

This scenario treats AI use in policy drafting as **medium- to high-risk**, particularly where policies have ethical, legal, or cultural implications.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI, clarify:

- the purpose and scope of the policy  
- which values and principles must guide it  
- what flexibility or discretion is intended  

Key awareness questions:

- What problem is this policy trying to solve?  
- Where are trade-offs unavoidable?  
- Which decisions require explicit justification?  

AI should be used to support clarity, not to resolve value tensions.

---

### 4.2 Human–AI Co-Agency

In policy drafting:

- humans define policy intent and boundaries  
- AI may assist with drafting and comparison  

Good co-agency means:

- AI-generated text is treated as provisional  
- policy owners actively interrogate wording  
- final language is explicitly human-approved  

Avoid:

- adopting AI-generated text without scrutiny  
- allowing AI to set policy direction implicitly  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- generating alternative phrasings for discussion  
- identifying inconsistencies across drafts  
- summarising consultation responses thematically  

Inappropriate uses include:

- finalising policy language autonomously  
- resolving disagreements by defaulting to AI  
- masking uncertainty with confident phrasing  

AI should function as a drafting partner, not an author.

---

### 4.4 Ethics, Equity and Impact

Policy drafting has significant ethical implications.

Use the Framework to ask:

- Who is affected by this policy, and how?  
- Does the language advantage or disadvantage particular groups?  
- Are equity considerations explicit or implicit?  

Ethical policy-making requires intentional articulation of values, not neutral-sounding text alone.

---

### 4.5 Decision-Making and Governance

Strong governance practices include:

- clear ownership of policy decisions  
- documentation of key design choices  
- transparent consultation and approval processes  

If AI is used:

- record its role in drafting  
- ensure traceability from draft to approved text  
- avoid creating opaque drafting histories  

This supports legitimacy and accountability.

---

### 4.6 Reflection, Learning and Renewal

After policy drafting sessions, reflect:

- Did AI use improve clarity or constrain debate?  
- Were important value judgements surfaced or hidden?  
- How can future policy development be improved?  

Reflection supports institutional learning, not just compliance.

---

## 5. In-the-Moment Prompts and Checks

### Human reflection prompts

- What values are we encoding here?  
- Where might this language be interpreted rigidly?  
- What discretion are we leaving to practice?  

### Optional AI prompts

- “Generate alternative phrasings that make underlying assumptions explicit.”  
- “Compare this draft with external policies, noting differences in values or scope.”  

### Pause and check

- Are we comfortable owning this policy language publicly?  
- Would stakeholders recognise their concerns in this draft?

---

## 6. After-Action Reflection

Following drafting and approval, consider:

- Did the policy achieve its intended clarity?  
- Where did interpretation diverge from intent?  
- How should the policy be reviewed or iterated?  

Use insights to inform future policy cycles.

---

## 7. What This Scenario Delivers

This scenario helps organisations to:

- draft policies more deliberately and transparently  
- avoid uncritical adoption of AI-generated norms  
- surface and document value judgements  
- strengthen governance and accountability  
- build mature AI capability in policy development contexts
