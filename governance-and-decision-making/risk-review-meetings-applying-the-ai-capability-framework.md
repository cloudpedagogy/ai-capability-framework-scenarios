# Risk Review Meetings — Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

---

## 1. Purpose of This Scenario

This scenario supports risk review meetings where potential harms, uncertainties, and trade-offs are formally examined. These meetings often occur in governance, quality assurance, ethics, research oversight, programme approval, or organisational risk management contexts.

Risk review meetings are high-stakes environments. AI may be introduced to analyse evidence, summarise risks, model scenarios, or prioritise issues. While such uses can support sensemaking, they also risk false confidence, opacity, or premature closure if not carefully governed.

The purpose of this scenario is to help professionals use AI as a bounded analytical aid, while ensuring that risk judgement, accountability, and responsibility remain firmly human.

This scenario is designed to support:

- Governance and risk committees  
- Ethics panels and review boards  
- Senior leaders and accountable officers  
- Academic and professional services staff involved in assurance processes  

---

## 2. Situation and Context

A risk review meeting is convened to examine:

- identified risks or incidents  
- emerging uncertainties  
- proposals requiring formal assurance  
- compliance, safety, ethical, or reputational concerns  

These meetings often involve:

- incomplete or contested information  
- diverse expertise and perspectives  
- pressure to reach defensible conclusions  

AI may be proposed to help synthesise documentation, identify patterns, or model possible outcomes. How it is used will shape the credibility and integrity of the risk review process.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in risk review meetings to:

- summarise large volumes of risk documentation  
- identify recurring themes or risk categories  
- model potential impacts or likelihoods  
- surface gaps in evidence or controls  

These uses matter because:

- AI-generated summaries may obscure uncertainty  
- probabilistic outputs can be misinterpreted as predictions  
- modelled risks may be treated as exhaustive  

This scenario treats AI use in risk review as **high-risk and high-responsibility**, requiring strong boundaries and oversight.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI in risk review, clarify:

- what type of risk is being examined (operational, ethical, reputational, safety)  
- what evidence is available and what is missing  
- what decisions or recommendations the meeting is authorised to make  

Key awareness questions:

- What uncertainties remain unresolved?  
- What assumptions underpin our risk framing?  
- Where might AI analysis create false reassurance?  

AI should be used to surface uncertainty, not eliminate it.

---

### 4.2 Human–AI Co-Agency

In risk review contexts:

- humans retain full responsibility for risk judgement  
- AI may assist with pattern recognition or scenario exploration  

Good co-agency means:

- AI outputs are treated as inputs, not conclusions  
- responsibility for risk acceptance or mitigation is explicit  
- accountable officers validate interpretations  

Avoid:

- deferring to AI-generated risk ratings  
- allowing models to substitute for deliberation  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- organising risk registers or evidence packs  
- highlighting potential interdependencies  
- generating alternative risk scenarios for discussion  

Inappropriate uses include:

- assigning final risk scores  
- determining acceptability of risk  
- automating mitigation decisions  

AI should support collective sensemaking, not decision automation.

---

### 4.4 Ethics, Equity and Impact

Risk review has ethical dimensions.

Use the Framework to ask:

- Whose risks are being prioritised or deprioritised?  
- Who bears the consequences if mitigation fails?  
- Could AI analysis reinforce existing power imbalances?  

Ethical risk review requires attention to distribution of harm and benefit, not just likelihood and impact.

---

### 4.5 Decision-Making and Governance

Strong governance practices include:

- clear documentation of risk judgements and rationales  
- separation of analysis from decision authority  
- alignment with organisational risk appetite and policy  

If AI is used:

- document its role and limitations  
- ensure transparency of assumptions  
- retain human-authored decision records  

This supports auditability and public trust.

---

### 4.6 Reflection, Learning and Renewal

After risk review meetings, reflect:

- Did AI use improve understanding or narrow thinking?  
- Were uncertainties adequately acknowledged?  
- How could future risk reviews be strengthened?  

Reflection supports institutional risk maturity, not just compliance.

---

## 5. In-the-Moment Prompts and Checks

### Human reflection prompts

- What risks are we least comfortable naming?  
- Where might our judgement be overconfident?  
- What would failure look like in practice?  

### Optional AI prompts

- “Summarise key risk themes while explicitly noting uncertainties and gaps.”  
- “Generate alternative risk scenarios based on different assumptions.”  

### Pause and check

- Are we treating AI outputs as analysis, not answers?  
- Would we defend this judgement without reference to AI?

---

## 6. After-Action Reflection

Following the meeting, consider:

- Were decisions and recommendations clearly documented?  
- Did AI use support or constrain critical discussion?  
- What should change in future risk review processes?  

Capture learning to improve organisational risk governance.

---

## 7. What This Scenario Delivers

This scenario helps organisations to:

- conduct more rigorous and transparent risk reviews  
- avoid false confidence driven by AI outputs  
- strengthen accountability and governance  
- integrate ethical and equity considerations into risk judgement  
- develop mature, reflective AI capability in high-stakes contexts
