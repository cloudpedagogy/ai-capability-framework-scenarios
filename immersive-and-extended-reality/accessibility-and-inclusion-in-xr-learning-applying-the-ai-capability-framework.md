# Accessibility and Inclusion in XR Learning: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0  

---

## 1. Purpose of This Scenario

This scenario supports the design, deployment, and review of **immersive learning experiences (XR, VR, AR, MR)** with a specific focus on **accessibility, inclusion, and equitable participation**.

Immersive technologies are often presented as inherently engaging or transformative. However, without intentional design, they can **exclude learners**, reinforce inequities, or create new barriers related to disability, neurodiversity, cost, culture, motion tolerance, or digital confidence.

The purpose of this scenario is to help organisations use AI-enabled immersive learning **without privileging a narrow definition of the “ideal” learner**, ensuring that access, choice, dignity, and fairness remain central.

This scenario is designed to support:

- Educators and curriculum designers  
- Learning technologists and XR developers  
- Disability services and accessibility leads  
- Quality assurance and ethics committees  
- Leaders responsible for inclusive innovation  

---

## 2. Situation & Context

An institution or organisation is introducing XR-based learning activities, such as:

- immersive simulations or labs  
- virtual fieldwork or site visits  
- roleplay-based professional training  
- experiential or scenario-based assessment  

At this stage:

- participation may be mandatory or optional  
- XR may replace or supplement existing formats  
- AI may personalise or adapt the experience  

Concerns begin to emerge around **who can participate fully**, **who may be disadvantaged**, and **whether inclusion has been meaningfully addressed or assumed**.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in XR learning to:

- personalise difficulty, pacing, or feedback  
- adapt interfaces or content dynamically  
- infer learner preferences or behaviours  
- automate accessibility features  

These uses matter because:

- personalisation may assume normative bodies or cognition  
- inferred needs may misrepresent learners  
- accessibility may be treated as a technical add-on rather than a design principle  
- exclusion may become invisible once XR is “the default”  

This scenario treats accessibility as **a core capability issue**, not a compliance afterthought.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before deploying XR learning, teams should clarify:

- who the learners are — in all their diversity  
- what barriers XR might introduce or amplify  
- what assumptions are embedded in the design  

Key awareness questions:

- Who might be unable, unwilling, or unsafe participating in XR?  
- What physical, sensory, cognitive, or financial barriers exist?  
- Are alternatives genuinely equivalent, or merely symbolic?  

AI should not be used to normalise exclusion through “adaptive” workarounds.

---

### 4.2 Human–AI Co-Agency

In inclusive XR design:

- humans remain responsible for equity and access  
- AI may assist with adaptation, not substitution  

Good co-agency means:

- learners can choose how they participate  
- AI-driven adaptations are transparent and optional  
- facilitators remain accountable for inclusion decisions  

Avoid:

- forcing XR participation because “AI will adapt”  
- outsourcing accessibility judgement to automated systems  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- offering multiple interaction modalities  
- supporting adjustable pacing or sensory load  
- enabling alternative representations of learning  

Inappropriate uses include:

- assuming AI personalisation solves accessibility  
- hiding exclusion behind technical complexity  
- treating non-XR alternatives as inferior  

AI should support **choice, flexibility, and dignity**.

---

### 4.4 Ethics, Equity & Impact

Accessibility is an ethical issue, not just a technical one.

Use the Framework to ask:

- Who benefits most from XR learning — and who bears the cost?  
- Are some learners expected to disclose needs to participate?  
- Does XR reinforce a narrow vision of competence or engagement?  

Ethical inclusion respects autonomy and avoids coercion.

---

### 4.5 Decision-Making & Governance

Strong governance practices include:

- accessibility review at design stage  
- documented rationale for XR adoption  
- clear guidance on alternatives and exemptions  

If AI is used:

- document assumptions about learners  
- review data collection and inference risks  
- ensure accountability for inclusion outcomes  

This supports defensible, equitable innovation.

---

### 4.6 Reflection, Learning & Renewal

After XR learning activities, reflect:

- Who participated fully — and who did not?  
- Where did barriers emerge unexpectedly?  
- How should design or policy change?  

Reflection ensures inclusion improves over time, not just once.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**

- Are learners exercising real choice?  
- Does anyone feel pressured to participate?  
- Are alternatives respected and valued?  

**Optional AI prompts**

- “Identify points where learners disengage or opt out.”  
- “Flag patterns suggesting accessibility barriers.”  

**Pause & check**

- Are we designing for people, or for technology?  
- Would we defend this as inclusive practice?

---

## 6. After-Action Reflection

Following XR learning:

- Were learning outcomes achieved equitably?  
- Did AI use reduce or introduce barriers?  
- What needs redesign, not justification?  

Use insights to strengthen inclusive capability practices.

---

## 7. What This Scenario Delivers

This scenario helps organisations:

- design inclusive XR learning environments  
- avoid exclusion masked as innovation  
- integrate accessibility into AI capability thinking  
- protect learner trust and dignity  
- build equitable, future-ready immersive learning systems  
