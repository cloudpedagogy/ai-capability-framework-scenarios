# AI-Driven Virtual Agents and Roleplay: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0  

---

## 1. Purpose of This Scenario

This scenario supports the use of **AI-driven virtual agents and roleplay characters** in immersive, simulated, or conversational environments. These agents may represent people, roles, stakeholders, patients, students, clients, or adversarial actors within learning, training, or rehearsal contexts.

AI-driven agents can enable scalable, repeatable roleplay experiences that would otherwise require human facilitators. However, when agents simulate human behaviour — including authority, emotion, judgement, or feedback — they can significantly shape participant beliefs, confidence, and decision-making.

The purpose of this scenario is to help organisations use AI-driven roleplay agents **responsibly and transparently**, ensuring that participants understand the limits of simulation and that **interpretation, judgement, and care remain human-led**.

This scenario is designed to support:

- Educators and trainers using roleplay or simulation  
- Learning designers and XR developers  
- Professional training and CPD leads  
- Researchers using simulated interaction  
- Ethics, safeguarding, and governance teams  

---

## 2. Situation & Context

An organisation is deploying or piloting AI-driven virtual agents to support:

- professional communication practice  
- difficult conversations or negotiation  
- ethical or pastoral scenarios  
- customer, patient, or stakeholder interaction  
- leadership, supervision, or conflict rehearsal  

Agents may:

- respond dynamically to participant input  
- display emotion, authority, or resistance  
- provide feedback or escalate scenarios  
- adapt behaviour based on participant choices  

At this point, decisions must be made about **role realism, feedback boundaries, and interpretive authority**.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI-driven agents may be used to:

- simulate human dialogue and behaviour  
- generate emotional or persuasive responses  
- escalate or de-escalate scenarios dynamically  
- provide automated feedback or summaries  

These uses matter because:

- participants may attribute authority or judgement to agents  
- emotional realism can amplify impact and vulnerability  
- AI responses may reflect hidden assumptions or bias  
- simulated feedback may be mistaken for evaluation  

This scenario treats AI-driven roleplay as **high-impact and psychologically sensitive**, even when framed as “practice only”.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before deploying AI-driven roleplay, teams should clarify:

- what the roleplay is intended to develop  
- whether the experience is exploratory or evaluative  
- what assumptions are embedded in agent behaviour  

Key awareness questions:

- What is this agent modelling — and what is it not?  
- Could participants interpret responses as judgement?  
- Where might realism obscure design intent?  

AI should be used to **support rehearsal and reflection**, not to simulate authority.

---

### 4.2 Human–AI Co-Agency

In AI-driven roleplay:

- humans remain responsible for meaning, learning, and interpretation  
- AI agents act as scripted or probabilistic representations  

Good co-agency means:

- facilitators frame the agent’s role explicitly  
- participants are reminded that agents are not people  
- feedback and conclusions are mediated by humans  

Avoid:

- positioning agents as evaluators or assessors  
- allowing AI feedback to stand without human context  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- enabling repeated, low-stakes rehearsal  
- exposing participants to varied interaction styles  
- supporting structured debrief and reflection  

Inappropriate uses include:

- rating participant performance automatically  
- simulating authority figures without safeguards  
- escalating emotional intensity without support  

AI should support **practice with care**, not pressure or judgement.

---

### 4.4 Ethics, Equity & Impact

AI-driven agents raise ethical concerns.

Use the Framework to ask:

- Could interactions cause distress or misinterpretation?  
- Do agent behaviours reflect cultural or social bias?  
- Are participants able to disengage or pause safely?  

Ethical roleplay prioritises consent, care, and inclusivity.

---

### 4.5 Decision-Making & Governance

Good governance practices include:

- transparency about how agents are designed and trained  
- clarity about whether interactions are recorded or analysed  
- safeguards around emotional and psychological impact  

If AI is used:

- disclose its role clearly  
- avoid repurposing interaction data without consent  
- ensure human oversight of feedback and follow-up  

This supports legitimacy and participant trust.

---

### 4.6 Reflection, Learning & Renewal

After AI-driven roleplay, reflect:

- How did the agent influence confidence or judgement?  
- Where did realism help or hinder learning?  
- What design assumptions should be revisited?  

Reflection supports ongoing improvement of immersive practice.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**

- What is this agent encouraging participants to do or believe?  
- Are participants treating the agent as authoritative?  
- Is emotional intensity appropriate and supported?  

**Optional AI prompts**

- “Generate alternative agent responses that reflect different assumptions.”  
- “Summarise key moments of tension or uncertainty in this interaction.”  

**Pause & check**

- Is AI supporting learning or shaping behaviour too strongly?  
- Should facilitation intervene or pause the interaction?

---

## 6. After-Action Reflection

Following AI-driven roleplay:

- Did participants understand the limits of the simulation?  
- Were any unintended emotional or ethical impacts observed?  
- How should agent behaviour be adjusted next time?  

Feed learning into design, facilitation, and governance processes.

---

## 7. What This Scenario Delivers

This scenario helps organisations:

- use AI-driven roleplay safely and transparently  
- avoid covert evaluation or authority simulation  
- protect participant wellbeing and trust  
- strengthen ethical oversight of immersive AI  
- build reflective, human-centred simulation capability  
