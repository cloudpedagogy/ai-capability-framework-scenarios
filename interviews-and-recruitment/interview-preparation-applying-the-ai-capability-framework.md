# Interview Preparation — Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

---

## 1. Purpose of This Scenario

This scenario supports preparing for interviews once a role has been designed and approved. It focuses on how interview questions, scoring criteria, and panel alignment are developed — a stage that strongly shapes fairness, consistency, and defensibility of recruitment decisions.

Interview preparation is a moment where AI is often introduced for convenience: drafting questions, refining wording, or creating scoring rubrics. Used well, AI can improve clarity and consistency. Used poorly, it can embed bias, narrow evaluation, or subtly influence judgement.

The purpose of this scenario is to help professionals use AI as a structured preparation aid, while ensuring that evaluation remains transparent, equitable, and firmly under human control.

This scenario is designed to support:

- Interview panel members  
- Panel chairs  
- Hiring managers  
- HR and people partners  

---

## 2. Situation and Context

An interview panel is preparing to assess candidates for a role that has already been scoped and approved. The panel must:

- agree on what good performance looks like  
- design questions that elicit relevant evidence  
- ensure consistency across candidates  

Common pressures at this stage include:

- limited preparation time  
- varying levels of interview experience across panel members  
- inherited or recycled question banks  
- informal or poorly documented scoring approaches  

AI may be considered to help speed up preparation, but this is also where small design choices can have outsized effects on candidate experience and outcomes.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI is commonly used at this stage to:

- draft interview questions aligned to role criteria  
- rewrite questions for clarity or tone  
- generate scoring rubrics or indicators  
- summarise role requirements into assessable dimensions  

These uses matter because:

- poorly designed questions advantage some candidates over others  
- vague criteria invite inconsistent judgement  
- AI-generated language can implicitly privilege dominant norms  

This scenario therefore treats AI use in interview preparation as **medium-risk but highly influential**, requiring deliberate boundaries and shared understanding.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before involving AI, the panel should clarify:

- what evidence they genuinely need from candidates  
- which aspects of the role can be assessed through interview questions  
- where interviews are not an appropriate assessment method  

Key awareness questions:

- What are we actually trying to learn from candidates?  
- Which criteria matter most for early success in the role?  
- Are we confusing confidence or fluency with capability?  

AI should be used to support clarity, not to invent assessment priorities.

---

### 4.2 Human–AI Co-Agency

In interview preparation:

- humans must define evaluation priorities  
- AI may assist with wording, structure, and consistency  

Good co-agency means:

- the panel agrees criteria before involving AI  
- AI outputs are reviewed collectively  
- final questions and rubrics are explicitly owned by the panel  

Avoid:

- allowing AI to rank or weight criteria  
- delegating judgement about what “good” looks like  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- generating multiple versions of a question for discussion  
- refining language to reduce ambiguity  
- drafting indicative scoring descriptors for calibration  

Inappropriate uses include:

- generating questions without panel review  
- producing automated scoring systems  
- using AI to predict candidate performance  

AI outputs should function as discussion prompts, not final artefacts.

---

### 4.4 Ethics, Equity and Impact

Interview preparation is a critical point for equity.

Key risks include:

- culturally specific phrasing  
- over-valuing past opportunities rather than potential  
- rewarding familiarity with organisational norms  

Use the Framework to ask:

- Do these questions privilege certain career paths?  
- Are we assessing potential or rehearsed performance?  
- Could this wording disadvantage non-traditional candidates?  

AI can help surface patterns, but equity judgements remain human responsibilities.

---

### 4.5 Decision-Making and Governance

Good governance at this stage includes:

- documenting agreed criteria and questions  
- ensuring consistency across candidates  
- retaining records of how questions were developed  

If AI is used:

- note its role in preparation  
- ensure transparency if challenged later  
- avoid creating the impression of automated assessment  

This supports defensibility and trust in the process.

---

### 4.6 Reflection, Learning and Renewal

After preparation, the panel should reflect:

- Were we aligned on what we wanted to assess?  
- Did AI clarify or confuse our priorities?  
- What should we improve next time?  

This reflection strengthens collective interview capability over time.

---

## 5. In-the-Moment Prompts and Checks

### Human reflection prompts

- What evidence would actually change our minds?  
- Are these questions genuinely distinct?  
- How will we ensure consistency across interviewers?  

### Optional AI prompts

- “Rewrite these questions to focus on observable behaviours rather than self-description.”  
- “Identify ambiguous or leading language in these interview questions.”  
- “Suggest scoring descriptors that emphasise evidence rather than confidence.”  

### Pause and check

- Would we be comfortable explaining these questions to an external reviewer?  
- Are we over-assessing what could be learned on the job?

---

## 6. After-Action Reflection

After interviews are complete:

- Did the questions elicit the evidence we expected?  
- Where did candidates struggle to interpret questions?  
- Did scoring feel consistent across the panel?  

Capture insights to refine future interview preparation.

---

## 7. What This Scenario Delivers

This scenario helps organisations to:

- design fairer and more consistent interviews  
- reduce bias introduced at the preparation stage  
- use AI responsibly without automating judgement  
- strengthen governance and defensibility  
- build collective interview capability over time
