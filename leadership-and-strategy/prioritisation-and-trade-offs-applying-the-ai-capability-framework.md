# Prioritisation and Trade-offs — Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

---

## 1. Purpose of This Scenario

This scenario supports leadership and strategy meetings where priorities must be set under constraint. These moments require making trade-offs between competing goals, values, resources, and risks — often with incomplete information and significant consequences.

AI is frequently introduced into prioritisation to rank options, optimise resource allocation, or model impacts. While these approaches can offer analytical clarity, they also risk masking value judgements, over-weighting measurable factors, or presenting trade-offs as technical rather than ethical choices.

The purpose of this scenario is to help leaders use AI to inform prioritisation conversations, while ensuring that trade-offs are surfaced explicitly and owned by humans.

This scenario is designed to support:

- Senior leadership teams  
- Strategy and portfolio managers  
- Programme and investment committees  
- Board members and governors  

---

## 2. Situation and Context

A prioritisation discussion is convened because:

- resources are limited (budget, time, people)  
- multiple initiatives compete for attention  
- external pressures require focus or reprioritisation  

These discussions often involve:

- conflicting organisational values  
- unequal distribution of impact  
- pressure to appear decisive and rational  

AI may be proposed to help rank options or model outcomes. How it is used will shape whether prioritisation feels legitimate, humane, and strategically sound.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in prioritisation and trade-offs to:

- score or rank initiatives against criteria  
- model resource allocation scenarios  
- estimate risks, costs, or benefits  
- visualise trade-offs across options  

These uses matter because:

- rankings can obscure underlying assumptions  
- optimisation can privilege efficiency over values  
- quantitative models may marginalise qualitative concerns  

This scenario treats AI use in prioritisation as **medium- to high-risk**, particularly where decisions have ethical, social, or long-term consequences.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI, leaders should clarify:

- what constraints are real versus assumed  
- which values are in tension  
- what success would look like from different perspectives  

Key awareness questions:

- What are we actually trading off here?  
- Which criteria reflect values, not just metrics?  
- Where might AI outputs simplify moral choices?  

AI should be used to illuminate trade-offs, not to hide them.

---

### 4.2 Human–AI Co-Agency

In prioritisation contexts:

- humans remain responsible for value judgements  
- AI may assist with scenario exploration  

Good co-agency means:

- leaders define criteria and weights consciously  
- AI outputs are interrogated, not accepted  
- final priorities are explicitly human decisions  

Avoid:

- allowing AI to determine priorities by default  
- treating optimisation as neutrality  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- exploring multiple prioritisation scenarios  
- visualising impacts of different trade-offs  
- stress-testing assumptions across options  

Inappropriate uses include:

- presenting a single ranked list as the answer  
- automating prioritisation without deliberation  
- excluding qualitative judgement from models  

AI should support deliberation, not replace it.

---

### 4.4 Ethics, Equity and Impact

Trade-offs always have ethical implications.

Use the Framework to ask:

- Who benefits and who bears the cost of each option?  
- Are certain impacts invisible in the data?  
- Does AI use amplify existing inequities?  

Ethical prioritisation requires explicit discussion of impact and fairness.

---

### 4.5 Decision-Making and Governance

Strong governance practices include:

- transparency about criteria and weighting  
- documentation of trade-off rationale  
- alignment with organisational mission and values  

If AI is used:

- document assumptions and limitations  
- ensure human sign-off on priorities  
- avoid opaque optimisation processes  

This supports accountability and trust.

---

### 4.6 Reflection, Learning and Renewal

After prioritisation decisions, reflect:

- Did the process feel fair and defensible?  
- Where did AI help or hinder judgement?  
- What should be revisited as conditions change?  

Reflection supports adaptive and values-aligned strategy.

---

## 5. In-the-Moment Prompts and Checks

### Human reflection prompts

- What are we choosing not to do — and why?  
- Which values are we privileging here?  
- What trade-offs would we struggle to justify publicly?  

### Optional AI prompts

- “Model alternative prioritisation scenarios using different value assumptions.”  
- “Visualise trade-offs between cost, impact, and equity across options.”  

### Pause and check

- Are we hiding judgement behind numbers?  
- Would we stand by these priorities if assumptions changed?

---

## 6. After-Action Reflection

Following prioritisation decisions:

- Were priorities implemented as intended?  
- Did consequences align with expectations?  
- How should prioritisation processes evolve?  

Feed learning into future strategic cycles.

---

## 7. What This Scenario Delivers

This scenario helps organisations to:

- make priorities explicit and defensible  
- surface and own trade-offs transparently  
- avoid AI-driven optimisation narratives  
- integrate ethics and equity into strategic decisions  
- build mature, reflective AI capability at leadership level
