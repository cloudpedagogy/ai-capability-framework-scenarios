# Sensemaking Under Uncertainty — Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

---

## 1. Purpose of This Scenario

This scenario supports leadership and strategy contexts where uncertainty is high and clarity is genuinely unavailable. It focuses on sensemaking — the collective process of interpreting signals, narratives, and partial evidence — rather than prediction or optimisation.

AI is increasingly used in uncertain contexts to synthesise information, detect patterns, or propose explanations. While this can support exploration, it also risks false coherence, premature closure, or overconfidence if AI outputs are mistaken for insight rather than interpretation.

The purpose of this scenario is to help leaders use AI to support shared sensemaking, while explicitly holding uncertainty, disagreement, and ambiguity as legitimate and necessary.

This scenario is designed to support:

- Senior leadership teams  
- Strategy and foresight groups  
- Boards and governors  
- Facilitators of complex decision-making processes  

---

## 2. Situation and Context

A sensemaking session is convened because:

- the environment is changing in unclear ways  
- signals are weak, contradictory, or emerging  
- past experience offers limited guidance  

Examples include:

- responding to technological disruption  
- navigating regulatory or political change  
- anticipating long-term societal shifts  

In these contexts, pressure often exists to:

- reduce ambiguity quickly  
- appear confident and decisive  
- settle on a single narrative  

AI may be proposed to analyse trends, cluster signals, or generate explanations. How it is used will shape whether uncertainty is explored productively or prematurely resolved.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in sensemaking under uncertainty to:

- cluster weak signals or emerging themes  
- summarise diverse sources of information  
- generate alternative interpretations or narratives  
- surface tensions or contradictions in data  

These uses matter because:

- clustering can imply coherence where none exists  
- summaries may privilege dominant narratives  
- generated explanations can feel convincing but unfounded  

This scenario treats AI use in sensemaking as **medium-risk but epistemically sensitive**, requiring careful facilitation and humility.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI, leaders should clarify:

- what is genuinely unknown  
- what assumptions are being held lightly  
- what would count as learning rather than certainty  

Key awareness questions:

- Are we seeking understanding or reassurance?  
- What are we not yet ready to decide?  
- Where might AI outputs give a false sense of clarity?  

AI should be used to expand perspectives, not to manufacture confidence.

---

### 4.2 Human–AI Co-Agency

In sensemaking contexts:

- humans remain responsible for interpretation and meaning  
- AI may assist with organising or provoking thought  

Good co-agency means:

- leaders frame questions to invite multiple interpretations  
- AI outputs are treated as hypotheses, not conclusions  
- disagreement and divergence are actively welcomed  

Avoid:

- converging too quickly around AI-generated narratives  
- treating AI pattern detection as truth  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- generating multiple, contrasting interpretations  
- surfacing anomalies or contradictions  
- supporting exploration of different frames  

Inappropriate uses include:

- selecting a single “best” explanation  
- forecasting outcomes without evidence  
- closing down discussion through confident synthesis  

AI should support exploration and curiosity, not resolution.

---

### 4.4 Ethics, Equity and Impact

Uncertainty often affects groups differently.

Use the Framework to ask:

- Whose experiences are shaping our sensemaking?  
- Which futures are being centred or marginalised?  
- Could AI use amplify dominant perspectives?  

Ethical sensemaking attends to plurality and power, not just patterns.

---

### 4.5 Decision-Making and Governance

Good governance under uncertainty includes:

- clarity about what is exploratory versus decided  
- documentation of assumptions and open questions  
- explicit review points as understanding evolves  

If AI is used:

- record its role in shaping interpretations  
- avoid embedding provisional narratives into policy prematurely  

This maintains flexibility and accountability.

---

### 4.6 Reflection, Learning and Renewal

After sensemaking sessions, reflect:

- Did AI use deepen understanding or narrow it?  
- Where did uncertainty remain — and should it?  
- How will learning be revisited as conditions change?  

Reflection supports adaptive leadership and ongoing learning.

---

## 5. In-the-Moment Prompts and Checks

### Human reflection prompts

- What stories are we telling ourselves?  
- What doesn’t fit our current narrative?  
- Where should we resist closure?  

### Optional AI prompts

- “Generate multiple interpretations of these signals without prioritising them.”  
- “Highlight contradictions or tensions across these data sources.”  

### Pause and check

- Are we mistaking coherence for insight?  
- Is AI helping us hold uncertainty productively?

---

## 6. After-Action Reflection

Following sensemaking sessions:

- What insights feel robust versus provisional?  
- What questions should remain open?  
- How will we revisit this sensemaking?  

Ensure outputs feed into future strategic reviews, not premature decisions.

---

## 7. What This Scenario Delivers

This scenario helps organisations to:

- engage uncertainty without rushing to closure  
- use AI to support collective sensemaking responsibly  
- avoid false certainty and narrative lock-in  
- strengthen strategic humility and adaptability  
- build mature AI capability for complex, ambiguous contexts
