# Follow-Up and Action: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

---

## 1. Purpose of This Scenario

This scenario supports turning meeting decisions into concrete follow-up actions while maintaining clarity of responsibility, proportional oversight, and trust. It focuses on what happens after decisions are captured: assigning actions, tracking progress, and communicating updates without creating unnecessary surveillance or administrative burden.

AI is often introduced here to automate reminders, draft follow-up communications, or track progress. Used well, it can reduce friction and support accountability. Used poorly, it can erode trust, obscure responsibility, or create the impression of automated management.

The purpose of this scenario is to help professionals use AI to support follow-through, while keeping ownership, judgement, and accountability firmly human.

This scenario is designed to support:
- Meeting chairs and facilitators  
- Project and programme leads  
- Committee secretaries and governance officers  
- Academic and professional services staff  

---

## 2. Situation & Context

A meeting has concluded and decisions have been formally recorded. Next steps typically involve:
- assigning actions to individuals or teams  
- setting timelines or review points  
- communicating outcomes to stakeholders  

Common challenges at this stage include:
- ambiguity about ownership  
- action lists that grow but are not prioritised  
- follow-up processes that feel bureaucratic or intrusive  

AI may be used to manage action tracking or communications. How it is introduced will shape trust, motivation, and delivery.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI is commonly used in follow-up and action to:
- draft follow-up emails or summaries  
- create task lists or reminders  
- track progress against actions  
- identify overdue or blocked items  

These uses matter because:
- automation can blur accountability  
- tracking tools can feel like surveillance  
- over-notification can reduce engagement  

This scenario treats AI use in follow-up as **low- to medium-risk**, provided proportionality and transparency are maintained.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI for follow-up, clarify:
- what level of tracking is appropriate  
- which actions genuinely need monitoring  
- how progress will be reviewed  

Key awareness questions:
- What follow-up is necessary versus performative?  
- Who needs visibility of progress?  
- What would feel supportive rather than controlling?  

AI should be used to reduce friction, not create it.

---

### 4.2 Human–AI Co-Agency

In follow-up processes:
- humans remain accountable for actions and outcomes  
- AI may assist with reminders and coordination  

Good co-agency means:
- ownership of actions is explicit and human  
- AI does not chase or escalate autonomously  
- individuals can query or adjust AI-generated follow-ups  

Avoid:
- automated escalation without human review  
- delegating performance judgement to AI  

---

### 4.3 Applied Practice

Appropriate AI uses include:
- drafting clear action summaries  
- scheduling reminders agreed by participants  
- consolidating updates for review meetings  

Inappropriate uses include:
- monitoring individual productivity  
- inferring reasons for delay  
- generating performance assessments  

AI should support coordination, not management by algorithm.

---

### 4.4 Ethics, Equity & Impact

Follow-up processes have equity implications.

Use the Framework to ask:
- Does follow-up disproportionately burden certain roles?  
- Are expectations realistic given capacity and context?  
- Could automated reminders disadvantage some colleagues?  

Ethical follow-up respects workload, autonomy, and trust.

---

### 4.5 Decision-Making & Governance

Good governance practices include:
- clarity about which actions are tracked formally  
- appropriate retention of action records  
- alignment with organisational reporting requirements  

If AI is used:
- be transparent about how tracking works  
- ensure humans review status summaries  
- avoid creating shadow accountability systems  

This maintains legitimacy and confidence in governance.

---

### 4.6 Reflection, Learning & Renewal

After follow-up cycles, reflect:
- Did actions progress as expected?  
- Where did follow-up processes help or hinder delivery?  
- How could AI use be improved next time?  

Reflection supports continuous improvement, not compliance.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- Are responsibilities clear and realistic?  
- Does follow-up support progress or create noise?  
- Who might need additional support?  

**Optional AI prompts**
- “Draft a concise follow-up summary listing agreed actions, owners, and review dates.”  
- “Identify actions that may require coordination across teams.”  

**Pause & check**
- Would this follow-up approach feel fair to those involved?  
- Are we using AI to help people succeed, not to police them?

---

## 6. After-Action Reflection

After a follow-up period:
- Were actions completed effectively?  
- Did AI use improve clarity and momentum?  
- What changes should be made to future follow-up practices?  

Use insights to refine meeting and action-tracking norms.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- translate decisions into action effectively  
- maintain clear human accountability  
- avoid surveillance-driven AI use  
- strengthen trust and follow-through  
- build sustainable, human-centred AI capability  
