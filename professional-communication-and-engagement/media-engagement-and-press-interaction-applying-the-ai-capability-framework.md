# Media Engagement and Press Interaction: Applying the AI Capability Framework

## 1. Purpose of This Scenario

This scenario supports media engagement and press interaction activities where organisations communicate with journalists, media outlets, or public audiences about research, policy, incidents, or institutional decisions.

Media moments are high-stakes. They shape public understanding, institutional reputation, trust, and accountability. AI is increasingly introduced to draft statements, prepare talking points, anticipate questions, or optimise messaging. While these uses can improve clarity and speed, they also risk over-polishing, exaggeration, loss of nuance, or the erosion of human responsibility if AI outputs are treated as authoritative.

The purpose of this scenario is to help professionals use AI, if at all, to **support preparedness and clarity** in media engagement — while ensuring that judgement, truthfulness, and accountability remain firmly human.

This scenario is designed to support:

- Communications and media relations teams  
- Senior leaders and institutional spokespeople  
- Researchers and subject-matter experts engaging with press  
- Policy, public affairs, and engagement professionals  
- Governance and risk leads involved in public communication  

---

## 2. Situation & Context

A media interaction is anticipated or underway. This may involve:

- responding to a journalist enquiry  
- preparing for an interview or press briefing  
- issuing a public statement or press release  
- addressing sensitive, contested, or high-profile issues  

These situations often involve:

- time pressure and limited opportunity for revision  
- asymmetric knowledge between organisation and audience  
- reputational and ethical risk  
- incentives to simplify, reassure, or defend  

AI may be proposed to draft messaging, predict likely questions, or refine tone. How it is used will shape whether communication is **credible and responsible** or **defensive and misleading**.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in media engagement to:

- draft press statements or briefing notes  
- summarise complex material for public explanation  
- anticipate questions or critique messaging  
- adjust tone for different audiences  

These uses matter because:

- AI-generated language can sound confident without being accurate  
- simplification may remove uncertainty or caveats  
- optimisation for clarity or reassurance can drift into spin  
- speed can displace reflection and ethical judgement  

This scenario treats AI use in media engagement as **high-risk**, given reputational, ethical, and public-interest implications.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI, teams should clarify:

- the purpose of the communication (inform, explain, respond, correct)  
- the level of uncertainty or contestation involved  
- what the public has a right to understand  

Key awareness questions:

- What must be accurate even if it is uncomfortable?  
- What uncertainty needs to remain visible?  
- Where could AI outputs over-state confidence or control?  

AI should be used to **support clarity**, not to manufacture certainty.

---

### 4.2 Human–AI Co-Agency

In media contexts:

- humans remain accountable for every public statement  
- AI may assist with drafting or rehearsal only  

Good co-agency means:

- spokespeople review and own all language  
- AI outputs are treated as preparatory material  
- final judgement about phrasing, emphasis, and disclosure is human  

Avoid:

- publishing AI-generated text without scrutiny  
- allowing AI to frame narratives implicitly  
- treating AI as a “safe” or neutral voice  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- drafting alternative phrasings for discussion  
- rehearsing responses to anticipated questions  
- checking clarity and accessibility of explanations  

Inappropriate uses include:

- generating definitive claims under uncertainty  
- minimising risk, harm, or controversy  
- automating public responses to sensitive enquiries  

AI should support **preparedness**, not **deflection**.

---

### 4.4 Ethics, Equity & Impact

Media communication has real-world consequences.

Use the Framework to ask:

- Who might be affected by how this is framed?  
- Could this communication mislead, reassure falsely, or exclude?  
- Does AI use amplify institutional power over public understanding?  

Ethical media engagement prioritises truthfulness, proportionality, and care.

---

### 4.5 Decision-Making & Governance

Strong governance practices include:

- clear authorisation for media statements  
- documentation of messaging decisions and assumptions  
- alignment with institutional values and legal obligations  

If AI is used:

- record its role in drafting or preparation  
- ensure human sign-off on all public outputs  
- avoid opaque or automated communication pipelines  

This supports accountability and reputational stewardship.

---

### 4.6 Reflection, Learning & Renewal

After media interactions, reflect:

- Did AI use support clarity or constrain honesty?  
- How was the communication received and interpreted?  
- What risks or gaps became visible?  

Reflection strengthens future media capability, not just message control.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**

- Would we stand by this wording if scrutinised publicly?  
- What uncertainty are we holding responsibly?  
- Are we communicating to inform or to manage perception?  

**Optional AI prompts**

- “Rewrite this response to preserve uncertainty and limitations.”  
- “Identify where this statement could be misinterpreted.”  

**Pause & check**

- Is AI helping us speak more clearly — or more safely?  
- Are we still exercising human judgement under pressure?  

---

## 6. After-Action Reflection

Following media engagement:

- Did communication align with values and evidence?  
- Were there unintended interpretations or consequences?  
- How should preparation or governance change next time?  

Use learning to improve future media engagement practices.

---

## 7. What This Scenario Delivers

This scenario helps organisations:

- engage with media more responsibly and confidently  
- avoid AI-driven over-confidence or spin  
- protect credibility under scrutiny  
- strengthen governance around public communication  
- build mature AI capability in high-stakes external engagement
