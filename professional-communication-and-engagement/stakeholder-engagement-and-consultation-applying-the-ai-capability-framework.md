# Stakeholder Engagement and Consultation: Applying the AI Capability Framework

## 1. Purpose of This Scenario

This scenario supports stakeholder engagement and consultation activities where organisations seek input, feedback, or perspectives from individuals or groups affected by decisions, policies, research, or change initiatives.

Consultation processes are inherently relational and political. They shape legitimacy, trust, inclusion, and perceived fairness — not just decision quality. While AI is increasingly introduced to synthesise responses, analyse themes, or draft consultation outputs, its use can unintentionally **flatten dissent**, **mask power dynamics**, or **create the illusion of participation without influence**.

The purpose of this scenario is to help professionals use AI, if at all, to **support listening, sensemaking, and transparency** in stakeholder engagement — while ensuring that consultation remains meaningful, ethical, and human-accountable.

This scenario is designed to support:

- Engagement and consultation leads  
- Policy and public affairs teams  
- Research and knowledge-exchange professionals  
- Change, transformation, and strategy teams  
- Governance, assurance, and ethics roles  

---

## 2. Situation & Context

A stakeholder engagement or consultation activity is being planned or conducted to:

- gather views, concerns, or lived experience  
- test proposals, policies, or directions  
- meet regulatory, ethical, or governance requirements  
- build legitimacy and trust around decisions  

Stakeholders may include:

- staff, students, or service users  
- community or public groups  
- partners, funders, or professional bodies  
- groups with unequal power, voice, or access  

Typical pressures include:

- large volumes of qualitative input  
- time and resource constraints  
- tension between openness and organisational agendas  
- expectations that consultation will lead to change  

AI may be proposed to summarise feedback, identify themes, or draft responses. How it is used will shape whether consultation feels **genuine** or **extractive**.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in stakeholder engagement to:

- cluster or summarise consultation responses  
- analyse recurring themes or sentiment  
- draft consultation reports or feedback summaries  
- generate responses to stakeholder input  

These uses matter because:

- aggregation can obscure minority or critical voices  
- thematic summaries may reflect organisational assumptions  
- AI-generated responses can sound respectful without being responsive  
- automation can distance decision-makers from lived experience  

This scenario treats AI use in consultation as **medium- to high-risk**, particularly where trust, inclusion, and legitimacy are at stake.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI, teams should clarify:

- the purpose of the consultation (inform, influence, decide)  
- what stakeholders are genuinely being asked to shape  
- how power and voice are distributed  

Key awareness questions:

- Are we listening to learn or to justify a direction?  
- What would meaningful influence look like here?  
- Where could AI unintentionally sanitise or soften challenge?  

AI should be used to **surface understanding**, not to manage perception.

---

### 4.2 Human–AI Co-Agency

In consultation contexts:

- humans remain responsible for interpretation, judgement, and response  
- AI may assist with organising and reviewing input  

Good co-agency means:

- humans define analytic lenses and priorities explicitly  
- AI outputs are treated as provisional summaries  
- decision-makers remain close to raw input where stakes are high  

Avoid:

- allowing AI to define “what matters most”  
- substituting synthesis for engagement  
- treating consultation outputs as neutral artefacts  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- generating multiple thematic groupings for comparison  
- highlighting areas of disagreement or tension  
- supporting internal reflection on consultation patterns  

Inappropriate uses include:

- reducing feedback to a single narrative  
- excluding inconvenient or minority perspectives  
- drafting “we listened” responses without substantive change  

AI should support **sensemaking and accountability**, not closure.

---

### 4.4 Ethics, Equity & Impact

Consultation processes have ethical implications.

Use the Framework to ask:

- Whose voices are most visible — and whose are not?  
- Are some groups bearing disproportionate risk or impact?  
- Could AI synthesis reproduce existing power imbalances?  

Ethical consultation prioritises **voice, care, and respect**, not efficiency alone.

---

### 4.5 Decision-Making & Governance

Strong governance practices include:

- clarity about how consultation input informs decisions  
- documentation of trade-offs and constraints  
- transparency about what changed — and what did not  

If AI is used:

- document how input was analysed  
- retain access to raw or minimally processed data  
- ensure human approval of consultation outputs  

This supports defensibility and public trust.

---

### 4.6 Reflection, Learning & Renewal

After consultation activities, reflect:

- Did stakeholders experience this as meaningful?  
- Where did AI use help or hinder understanding?  
- What capability gaps became visible?  

Reflection strengthens future engagement — not just reporting.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**

- What are stakeholders telling us that is uncomfortable?  
- Where are we tempted to smooth or summarise too quickly?  
- Are we hearing difference as signal or as noise?  

**Optional AI prompts**

- “Summarise themes while explicitly highlighting minority or dissenting views.”  
- “Identify tensions or contradictions across stakeholder input.”  

**Pause & check**

- Would stakeholders recognise themselves in this summary?  
- Are we using AI to listen better — or to move on faster?  

---

## 6. After-Action Reflection

Following consultation:

- What influence did stakeholder input actually have?  
- How were decisions communicated back?  
- Where should engagement practices change next time?  

Use learning to strengthen legitimacy and trust over time.

---

## 7. What This Scenario Delivers

This scenario helps organisations:

- conduct more ethical and credible consultation  
- avoid AI-driven flattening of stakeholder voice  
- strengthen transparency and accountability  
- build trust through genuine engagement  
- develop mature AI capability in participatory contexts  
