# Redefining Expertise with AI: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0  

---

## 1. Purpose of This Scenario

This scenario supports professionals who are questioning what *expertise* means in AI-mediated work.

As generative AI becomes embedded in everyday professional practice, long-standing markers of expertise — speed, recall, fluency, technical mastery — are being destabilised. Tasks that once signalled competence can now be performed, assisted, or simulated by AI systems.

This scenario focuses on the **identity-level shift** that accompanies this change. It helps professionals reflect on how expertise is being redefined, how legitimacy is negotiated, and how responsibility and judgement remain human even as capability is redistributed.

The purpose is not to defend traditional expertise nor to embrace AI uncritically, but to support **credible, grounded re-articulation of professional value**.

This scenario is designed to support:
- Experienced professionals and specialists  
- Academic and research staff  
- Senior professional services and public-sector roles  
- CPD and leadership development programmes  

---

## 2. Situation & Context

You are an experienced professional in a role where expertise has historically been demonstrated through:
- depth of knowledge  
- speed and accuracy of response  
- command of complex information  
- recognised professional authority  

AI tools are now present in your domain. They may:
- draft analyses or explanations  
- summarise complex material instantly  
- generate plausible responses across many topics  
- reduce the visible effort involved in expert work  

Colleagues, managers, or stakeholders may begin to ask:
- “If AI can do this, what is the expert’s role now?”
- “What does competence look like in this new context?”
- “How do we know who to trust?”

You may feel:
- uncertainty about how your expertise is perceived  
- pressure to demonstrate relevance or fluency with AI  
- discomfort when AI outputs resemble your own work  
- concern about being seen as resistant, obsolete, or replaceable  

You decide to use the AI Capability Framework to **reframe expertise around judgement, responsibility, and context**, rather than task execution alone.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in this context to:
- generate expert-sounding explanations or recommendations  
- support analysis or interpretation  
- draft professional communications  
- simulate expert reasoning  

These uses matter because:
- AI outputs can mimic surface features of expertise  
- confidence and fluency can be mistaken for judgement  
- organisational signals about “value” may shift implicitly  
- professionals may feel pressured to perform AI-augmented competence  

This scenario treats AI use as **identity-shaping**, not just productivity-enhancing.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Begin by clarifying:
- how expertise has traditionally been recognised in your role  
- which aspects of your work are now AI-assisted or AI-replicable  
- which aspects remain fundamentally human  

Key awareness questions:
- What does *expertise* actually consist of in my context?
- Which parts of my work involve judgement, not just output?
- Where might AI outputs be mistaken for understanding?

AI can surface information, but it does not hold responsibility for meaning, consequence, or appropriateness.

---

### 4.2 Human–AI Co-Agency

Redefining expertise requires re-establishing agency boundaries.

In this scenario:
- humans remain accountable for interpretation, decisions, and outcomes  
- AI may support exploration, drafting, or synthesis  
- expertise is demonstrated through *how* AI is used and governed  

Good co-agency means:
- experts frame problems deliberately before involving AI  
- AI outputs are interrogated, not accepted  
- professionals retain ownership of final judgements  

Avoid:
- equating AI fluency with expertise  
- outsourcing professional authority to AI systems  

---

### 4.3 Applied Practice

Credible redefinition of expertise involves visible practice.

Examples include:
- articulating how AI supports, rather than replaces, expert judgement  
- explicitly distinguishing between AI-generated input and human decision  
- modelling careful validation, contextualisation, and restraint  

Inappropriate practices include:
- presenting AI outputs as personal expertise  
- hiding AI use to preserve perceived authority  
- deferring difficult judgement to AI recommendations  

Expertise becomes visible through **discernment**, not speed.

---

### 4.4 Ethics, Equity & Impact

Shifts in expertise affect power and inclusion.

Use the Framework to ask:
- Whose expertise is being amplified or diminished by AI?
- Are certain forms of knowledge being privileged or erased?
- Could AI use undermine trust in professional roles?

Ethical expertise involves:
- recognising asymmetries in confidence and access  
- resisting performative displays of AI fluency  
- maintaining honesty about limits and uncertainty  

---

### 4.5 Decision-Making & Governance

Expertise is inseparable from accountability.

Good governance practices include:
- clear statements about who is responsible for decisions  
- documentation of where AI informed judgement  
- resistance to informal delegation of authority to AI systems  

If AI is used:
- ensure professional accountability remains explicit  
- avoid ambiguity about authorship or responsibility  
- maintain defensible decision trails  

Expertise is ultimately demonstrated by **owning consequences**.

---

### 4.6 Reflection, Learning & Renewal

This scenario strongly activates the Framework’s renewal domain.

Reflect on:
- How has my understanding of expertise shifted?
- Where do I now add the most value?
- What aspects of my role require deeper judgement, not automation?

Renewal involves:
- letting go of outdated performance signals  
- investing in interpretive, ethical, and relational capability  
- mentoring others through similar identity transitions  

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What am I being trusted to decide here?
- Where does judgement matter more than output?
- What would responsible restraint look like?

**Optional AI prompts**
- “Generate alternative interpretations of this issue and note their limitations.”
- “What contextual factors might an expert need to consider beyond this output?”

**Pause & check**
- Am I using AI to support expertise — or to perform it?
- Would I stand by this decision without the AI?

---

## 6. After-Action Reflection

After AI-mediated work:
- Did my role as an expert feel clearer or more ambiguous?
- Where did AI support good judgement?
- Where did it risk obscuring responsibility?

Capture insights about:
- how expertise is recognised  
- how trust is maintained  
- how professional value is communicated  

---

## 7. What This Scenario Delivers

This scenario helps professionals and organisations:
- redefine expertise credibly in AI-mediated contexts  
- protect judgement, accountability, and trust  
- avoid performative or defensive AI use  
- support identity transition without loss of legitimacy  
- build durable, human-centred AI capability  

