# Algorithmic Decision Appeals and Redress: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0  

---

## 1. Purpose of This Scenario

This scenario supports **appeals, complaints, and redress processes** where individuals or organisations challenge decisions that were informed, influenced, or mediated by AI.

Appeals are the point where abstract commitments to fairness, transparency, and accountability are tested in practice. When AI is involved, there is a heightened risk that decisions become difficult to explain, difficult to challenge, or implicitly treated as more objective than they are.

The purpose of this scenario is to help organisations design and operate appeal processes that remain **human-led, intelligible, and just**, even when AI systems have shaped outcomes.

This scenario is designed to support:

- Appeals and complaints teams  
- Caseworkers and adjudicators  
- Legal and regulatory staff  
- Ombudsman and review bodies  
- Public service and regulatory organisations  

---

## 2. Situation & Context

An individual or organisation has challenged a decision that:

- affects rights, access, or entitlements  
- has significant personal, financial, or reputational impact  
- involved AI-supported analysis, prioritisation, or recommendation  

Examples include:

- benefits or eligibility determinations  
- regulatory enforcement actions  
- risk-based prioritisation or screening  
- service access or resource allocation decisions  

At this point, the organisation must demonstrate that the decision is **reviewable, explainable, and accountable** — not simply “the output of a system”.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be present in appeals and redress processes through:

- original decision-support tools  
- case triage or prioritisation systems  
- summarisation of appeal materials  
- pattern analysis across complaints  

These uses matter because:

- system logic may be opaque or proprietary  
- automated summaries can bias interpretation  
- reliance on original AI outputs can entrench error  
- power asymmetries are heightened  

This scenario treats AI use in appeals as **high-risk and high-accountability**.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before handling an appeal, teams should clarify:

- what role AI played in the original decision  
- what aspects of the decision are contestable  
- what standards of explanation and review apply  

Key awareness questions:

- What is the appellant actually challenging?  
- Where might AI have shaped assumptions or thresholds?  
- What uncertainty or discretion exists?  

AI should never be treated as closing off avenues of challenge.

---

### 4.2 Human–AI Co-Agency

In appeal contexts:

- humans must remain the final arbiters of judgement  
- AI outputs are inputs, not authorities  
- review processes must allow meaningful challenge  

Good co-agency means:

- reviewers understand system limitations  
- AI outputs can be overridden or discounted  
- responsibility is clearly human and named  

Avoid:

- stating that decisions “cannot be changed” due to AI  
- deferring judgement to technical explanations  
- requiring appellants to challenge the system rather than the decision  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- organising large case files for review  
- identifying comparable past cases for consistency checks  
- supporting transparency in explanation  

Inappropriate uses include:

- re-running the same model as a form of review  
- auto-generating appeal outcomes  
- filtering appeals based on predicted success  

AI should support **procedural fairness**, not efficiency at the expense of justice.

---

### 4.4 Ethics, Equity & Impact

Appeals processes are ethically charged.

Use the Framework to ask:

- Are some groups less able to challenge AI-informed decisions?  
- Does technical complexity disadvantage appellants?  
- Could automation reinforce structural inequity?  

Ethical redress requires accessibility, patience, and care.

---

### 4.5 Decision-Making & Governance

Strong governance includes:

- clear appeal rights and pathways  
- documentation of original and reviewed decisions  
- separation between decision-making and appeal functions  

If AI is involved:

- record its role in the original decision  
- ensure appeal reviewers are not bound by AI outputs  
- retain evidence necessary for audit and legal review  

This supports legitimacy and procedural justice.

---

### 4.6 Reflection, Learning & Renewal

After appeals are resolved, reflect:

- What patterns of challenge are emerging?  
- Are certain AI-informed decisions disproportionately appealed?  
- What should change upstream?  

Appeals should feed organisational learning, not be treated as exceptions.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**

- Could we explain this decision clearly to a lay audience?  
- Are we reviewing the decision — or defending the system?  
- What discretion do we have, and are we using it responsibly?  

**Optional AI prompts**

- “Identify assumptions embedded in this decision logic.”  
- “Summarise alternative interpretations of this case.”  

**Pause & check**

- Would this process feel fair from the appellant’s position?  
- Is AI helping scrutiny — or shielding the decision?  

---

## 6. After-Action Reflection

Following appeal resolution:

- Was the process experienced as fair and intelligible?  
- Did AI complicate or clarify review?  
- What governance or design changes are needed?  

Use insights to strengthen future decision and appeal systems.

---

## 7. What This Scenario Delivers

This scenario helps organisations:

- uphold procedural fairness in AI-informed decisions  
- maintain human accountability under challenge  
- design defensible and reviewable systems  
- reduce reputational and legal risk  
- build trustworthy AI capability in public-facing decision contexts  
