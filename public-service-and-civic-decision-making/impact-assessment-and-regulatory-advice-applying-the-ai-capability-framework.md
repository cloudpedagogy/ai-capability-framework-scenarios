# Impact Assessment and Regulatory Advice: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0  

---

## 1. Purpose of This Scenario

This scenario supports the use of AI in **impact assessment and regulatory advice**, where public bodies evaluate potential social, economic, environmental, or ethical consequences of proposed policies, regulations, or interventions.

Impact assessment is a critical decision point in public service. It informs whether policies proceed, how risks are mitigated, and how trade-offs are justified. Increasingly, AI is being proposed to model impacts, synthesise evidence, forecast outcomes, or draft advisory reports.

The purpose of this scenario is to help policy and regulatory teams use AI **without overstating certainty, masking assumptions, or displacing professional judgement**, ensuring that advice remains credible, transparent, and defensible.

This scenario is designed to support:

- Policy analysts and regulatory advisers  
- Impact assessment and evaluation teams  
- Legal and regulatory policy units  
- Economists, social researchers, and risk specialists  
- Cross-agency advisory groups  

---

## 2. Situation & Context

An organisation is preparing regulatory advice or an impact assessment for:

- a new or revised policy proposal  
- a regulatory change or enforcement approach  
- a public-sector programme or intervention  
- a response to emerging risk or societal concern  

The assessment must consider:

- multiple forms of evidence  
- uncertainty and long-term effects  
- trade-offs between competing objectives  
- scrutiny from ministers, courts, media, and the public  

AI may be introduced to synthesise evidence, model scenarios, or draft sections of the assessment. How it is used will shape **how risks are framed, whose interests are foregrounded, and how uncertainty is communicated**.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in impact assessment and regulatory advice to:

- summarise large evidence bases  
- model or forecast potential impacts  
- compare policy options or scenarios  
- draft explanatory or advisory text  

These uses matter because:

- models may embed hidden assumptions  
- forecasts can convey false precision  
- summaries may prioritise measurable impacts over lived experience  
- AI-generated advice can sound authoritative without warrant  

This scenario treats AI use in impact assessment as **high-risk and high-accountability**, requiring careful governance.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI, teams should clarify:

- the purpose of the assessment (exploration, justification, risk mitigation)  
- what forms of evidence are being considered  
- where uncertainty and judgement are unavoidable  

Key awareness questions:

- What decisions will this advice inform?  
- Where might AI overstate confidence or neutrality?  
- What assumptions are embedded in models or datasets?  

AI should be used to **illuminate uncertainty**, not to conceal it.

---

### 4.2 Human–AI Co-Agency

In regulatory advice contexts:

- humans remain responsible for interpretation and recommendations  
- AI may assist with organisation, modelling, or drafting  
- accountability for advice remains explicitly human  

Good co-agency means:

- modelling choices and parameters are human-defined  
- AI outputs are reviewed critically and comparatively  
- professional judgement overrides automated outputs where needed  

Avoid:

- treating AI forecasts as objective truth  
- delegating normative judgement to tools  
- presenting AI outputs as independent validation  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- exploring multiple impact scenarios under different assumptions  
- stress-testing policy options for unintended consequences  
- supporting clarity and structure in advisory documentation  

Inappropriate uses include:

- presenting AI-generated projections as predictions  
- excluding qualitative or experiential evidence  
- automating recommendations without deliberation  

AI should support **advisory rigour**, not shortcut it.

---

### 4.4 Ethics, Equity & Impact

Impact assessment is inherently ethical.

Use the Framework to ask:

- Who benefits and who bears risk under each option?  
- Are impacts distributed unevenly across communities?  
- Could AI modelling obscure equity concerns?  

Ethical regulatory advice requires explicit attention to justice, proportionality, and harm.

---

### 4.5 Decision-Making & Governance

Good governance practices include:

- clear documentation of methods, assumptions, and limitations  
- separation between analysis and recommendation  
- traceability from evidence to advice  

If AI is used:

- record tools, models, and data sources  
- ensure advice remains human-authored and signed off  
- avoid opaque or irreproducible analysis  

This supports legal defensibility and institutional credibility.

---

### 4.6 Reflection, Learning & Renewal

After advice is delivered, reflect:

- How did AI use shape framing or confidence levels?  
- Where did uncertainty remain unresolved?  
- What governance safeguards need strengthening?  

Reflection supports continuous improvement in regulatory capability.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**

- What assumptions are doing the most work here?  
- Where are we relying on proxies rather than evidence?  
- How might this advice be challenged publicly or legally?  

**Optional AI prompts**

- “Generate alternative impact scenarios using different assumptions.”  
- “Identify where evidence is weak, contested, or absent.”  

**Pause & check**

- Are we mistaking model output for judgement?  
- Is AI clarifying risk — or masking it?  

---

## 6. After-Action Reflection

Following regulatory advice:

- How was uncertainty communicated to decision-makers?  
- Did AI use support or undermine confidence in the advice?  
- What learning should inform future assessments?  

Use insights to refine analytical and governance practices.

---

## 7. What This Scenario Delivers

This scenario helps organisations:

- use AI responsibly in high-stakes regulatory advice  
- avoid false certainty and automation bias  
- strengthen transparency and defensibility  
- integrate equity into impact assessment  
- build mature AI capability in public-sector decision-making  
