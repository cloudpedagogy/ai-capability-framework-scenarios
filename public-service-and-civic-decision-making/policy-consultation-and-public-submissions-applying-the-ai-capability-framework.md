# Policy Consultation and Public Submissions: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0  

---

## 1. Purpose of This Scenario

This scenario supports the use of AI during **policy consultation and public submission processes**, where governments, regulators, or public bodies invite feedback, evidence, and perspectives from stakeholders and the public.

Public consultation is a cornerstone of democratic governance. It shapes policy legitimacy, public trust, and institutional accountability. Increasingly, AI is being introduced to support consultation processes — summarising submissions, clustering themes, drafting responses, or analysing sentiment at scale.

The purpose of this scenario is to help policy teams use AI **without undermining deliberation, pluralism, or fairness**, ensuring that consultation remains a genuine mechanism for listening, judgement, and accountable decision-making — not a procedural shortcut.

This scenario is designed to support:

- Policy officials and analysts  
- Public consultation and engagement teams  
- Regulatory and advisory bodies  
- Cross-agency policy working groups  
- External consultants supporting consultation processes  

---

## 2. Situation & Context

A public consultation is underway or has recently closed. The organisation has received:

- written submissions from individuals and community groups  
- responses from sector bodies, unions, or professional associations  
- advocacy-driven or values-based statements  
- technical, legal, or operational feedback  

Typical pressures include:

- very large volumes of submissions  
- limited time and analytical capacity  
- political, ministerial, or media scrutiny  
- expectations of transparency and responsiveness  
- competing interpretations of what “the public” is saying  

AI may be proposed to accelerate synthesis, identify themes, or generate draft summaries. How it is used will shape **whose voices are heard, how disagreement is represented, and how policy decisions are justified**.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in consultation processes to:

- cluster or categorise submissions  
- summarise themes, arguments, or concerns  
- identify frequently raised issues  
- draft consultation outcome reports or responses  

These uses matter because:

- volume-based analysis can privilege organised or well-resourced groups  
- summarisation can flatten disagreement or nuance  
- clustering may obscure minority, marginal, or dissenting perspectives  
- AI-generated summaries can be mistaken for public consensus  

This scenario treats AI use in consultation analysis as **high-impact and politically sensitive**, requiring explicit boundaries and human judgement.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI, teams should clarify:

- the purpose of the consultation (exploration, evidence-gathering, legitimacy, refinement)  
- how consultation input will influence decisions  
- the difference between representation, evidence, and opinion  

Key awareness questions:

- What does this consultation need to surface — consensus, diversity, or contestation?  
- Where might AI distort the apparent weight of views?  
- What assumptions about “public opinion” could AI reinforce?  

AI should be used to **surface complexity**, not to manufacture clarity.

---

### 4.2 Human–AI Co-Agency

In consultation contexts:

- humans remain responsible for interpretation and judgement  
- AI may assist with organisation, pattern detection, or drafting  
- accountability for meaning and decision-making remains human  

Good co-agency means:

- consultation questions and categories are human-defined  
- AI outputs are treated as provisional analytical artefacts  
- officials actively interrogate and contextualise summaries  

Avoid:

- allowing AI outputs to define “what the public thinks”  
- treating automated synthesis as neutral or objective  
- delegating interpretive judgement to tools  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- organising submissions to support human review  
- generating multiple thematic summaries for comparison  
- highlighting areas of disagreement or uncertainty  
- supporting transparency through clear documentation  

Inappropriate uses include:

- reducing consultation to sentiment scores or rankings  
- filtering out low-frequency but high-significance views  
- presenting AI summaries as definitive findings  

AI should support **interpretive work**, not replace it.

---

### 4.4 Ethics, Equity & Impact

Public consultation carries equity implications.

Use the Framework to ask:

- Whose voices are amplified or marginalised by AI processing?  
- Are certain communities over- or under-represented?  
- Could AI reinforce existing power imbalances?  

Ethical consultation requires care, proportionality, and attention to inclusion — not just efficiency.

---

### 4.5 Decision-Making & Governance

Good governance practices include:

- transparency about how submissions are analysed  
- documentation of analytical methods and assumptions  
- clear separation between consultation input and policy decisions  

If AI is used:

- record its role in analysis and reporting  
- avoid relying solely on AI-generated summaries  
- ensure decision rationales remain explicit and human-authored  

This supports legitimacy, auditability, and public trust.

---

### 4.6 Reflection, Learning & Renewal

After the consultation process, reflect:

- Did AI use help surface meaningful insight or obscure it?  
- Were dissenting or minority views visible?  
- How did AI shape perceptions of consensus or disagreement?  

Reflection strengthens institutional capability for future public engagement.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**

- What voices might this summary be missing?  
- Where is disagreement being smoothed over?  
- Are we mistaking frequency for importance?  

**Optional AI prompts**

- “Summarise key themes, explicitly noting disagreement and uncertainty.”  
- “Identify low-frequency submissions raising high-impact concerns.”  

**Pause & check**

- Would stakeholders recognise this summary as fair?  
- Is AI helping us listen — or helping us conclude too quickly?  

---

## 6. After-Action Reflection

Following the consultation:

- How was AI use communicated publicly?  
- Did AI-assisted analysis support or undermine trust?  
- What safeguards should be strengthened next time?  

Use learning to refine consultation design and analytical governance.

---

## 7. What This Scenario Delivers

This scenario helps organisations:

- analyse public consultation input responsibly  
- avoid false consensus and automation bias  
- protect democratic legitimacy and transparency  
- document defensible decision-making  
- build mature AI capability in public-facing policy work  
