# Public Communication of AI-Informed Decisions: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0  

---

## 1. Purpose of This Scenario

This scenario supports **public communication** where AI has informed, supported, or shaped decisions that affect citizens, communities, or public services.

Public communication is not simply about explaining outcomes — it is about maintaining **legitimacy, trust, and accountability**. When AI has been involved, even indirectly, communication choices determine whether decisions are perceived as reasoned, fair, and human-led, or as opaque, technocratic, and unchallengeable.

The purpose of this scenario is to help organisations communicate AI-informed decisions **honestly and proportionately**, without overstating objectivity, concealing uncertainty, or deflecting responsibility onto technology.

This scenario is designed to support:

- Public sector communications teams  
- Policy leads and senior responsible officers  
- Ministers’ offices and briefing teams  
- Public engagement and consultation staff  
- Legal and governance advisers  

---

## 2. Situation & Context

An organisation must communicate a decision that:

- affects the public directly or indirectly  
- has political, social, or reputational sensitivity  
- may be scrutinised by media, courts, or civil society  
- involved AI in analysis, modelling, prioritisation, or drafting  

Examples include:

- announcing policy changes  
- publishing regulatory decisions  
- responding to public concern or challenge  
- issuing formal explanations or justifications  

AI may have been used behind the scenes. Whether and how this is communicated will shape **public understanding, trust, and perceived accountability**.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in public communication to:

- draft explanations, FAQs, or press materials  
- tailor messaging for different audiences  
- summarise complex decision rationales  
- anticipate public reactions or questions  

These uses matter because:

- AI-generated explanations can sound overly confident  
- messaging optimisation may prioritise reassurance over honesty  
- simplified narratives may erase uncertainty or dissent  
- responsibility can appear displaced onto “the system”  

This scenario treats AI use in public communication as **medium- to high-risk with high reputational impact**.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before communicating, teams should clarify:

- what decision was made and why  
- how AI influenced the process (if at all)  
- what uncertainty or contestability remains  

Key awareness questions:

- What does the public need to understand — not just accept?  
- Where might AI involvement be misunderstood?  
- What would transparency reasonably require here?  

AI should not be used to **smooth over complexity that matters**.

---

### 4.2 Human–AI Co-Agency

In public communication:

- humans remain accountable for decisions and explanations  
- AI may assist with drafting or structuring messages  
- final framing and tone are human choices  

Good co-agency means:

- communications are reviewed and approved by accountable leaders  
- AI outputs are treated as drafts, not final explanations  
- responsibility is never attributed to AI systems  

Avoid:

- phrasing that implies decisions were “made by AI”  
- using AI language to deflect criticism  
- presenting AI as neutral authority  

---

### 4.3 Applied Practice

Appropriate AI uses include:

- drafting multiple explanatory versions for review  
- clarifying complex reasoning in accessible language  
- identifying areas likely to require further explanation  

Inappropriate uses include:

- generating justifications after decisions are fixed  
- removing uncertainty to reduce perceived risk  
- automating public responses without oversight  

AI should support **clarity with integrity**, not reassurance by omission.

---

### 4.4 Ethics, Equity & Impact

Public communication has ethical consequences.

Use the Framework to ask:

- Who might be affected differently by this decision?  
- Are some communities more exposed to harm or misunderstanding?  
- Does AI-mediated framing privilege institutional perspective?  

Ethical communication respects the public’s right to understand and question.

---

### 4.5 Decision-Making & Governance

Good governance includes:

- alignment between internal records and public explanations  
- consistency with freedom of information and disclosure obligations  
- clarity about what can and cannot be said  

If AI is used:

- document its role in drafting or analysis  
- ensure legal and governance review of final messaging  
- avoid creating discrepancies between internal and external accounts  

This supports defensibility and institutional trust.

---

### 4.6 Reflection, Learning & Renewal

After communication, reflect:

- How was the explanation received and interpreted?  
- Did AI use improve clarity or reduce credibility?  
- What transparency expectations are evolving?  

Reflection strengthens future public engagement practices.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**

- Would we stand by this explanation under scrutiny?  
- Where are we simplifying responsibly — and where are we oversimplifying?  
- Are we clearly owning the decision?  

**Optional AI prompts**

- “Rewrite this explanation to retain uncertainty and limits.”  
- “Identify statements that may imply false objectivity or inevitability.”  

**Pause & check**

- Are we communicating to inform — or to contain reaction?  
- Is AI supporting trust, or eroding it?  

---

## 6. After-Action Reflection

Following public communication:

- Were key questions answered or deflected?  
- Did AI involvement become a point of concern?  
- How should future communications change?  

Feed insights into communication and governance processes.

---

## 7. What This Scenario Delivers

This scenario helps organisations:

- communicate AI-informed decisions transparently  
- avoid reputational damage from over-automation narratives  
- maintain human accountability in public explanation  
- respect public trust and democratic scrutiny  
- build mature AI capability in public communication contexts  
