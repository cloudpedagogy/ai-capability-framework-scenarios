# Analysis and Interpretation: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

---

## 1. Purpose of This Scenario

This scenario supports analysis and interpretation phases of research and knowledge work, where data, evidence, or materials are examined to generate findings, insights, or claims. These phases are epistemically sensitive: choices about methods, framing, and interpretation directly shape what counts as knowledge.

AI is increasingly introduced to assist with coding, pattern detection, summarisation, modelling, or exploratory analysis. While these capabilities can extend analytical capacity, they also risk overfitting, confirmation bias, spurious pattern recognition, or the reification of correlations as explanations if not carefully governed.

The purpose of this scenario is to help teams use AI to augment analysis while protecting interpretive judgement, methodological integrity, and epistemic humility.

This scenario is designed to support:
- Researchers and analysts across disciplines  
- Data scientists and qualitative researchers  
- Supervisors and research leads  
- Teams working with complex or mixed-methods evidence  

---

## 2. Situation & Context

Analysis and interpretation occur when:
- data collection is complete or ongoing  
- preliminary findings are emerging  
- teams must decide what evidence means  

Typical challenges include:
- large or heterogeneous datasets  
- ambiguous or conflicting signals  
- pressure to produce clear results  

AI may be proposed to accelerate analysis, reveal patterns, or generate summaries. How it is used will shape whether interpretation remains rigorous or becomes automated.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in analysis and interpretation to:
- cluster or code qualitative data  
- identify statistical patterns or anomalies  
- summarise large bodies of text or results  
- generate hypotheses or explanations  

These uses matter because:
- pattern detection can privilege frequency over significance  
- summaries may collapse nuance and dissent  
- generated explanations can sound plausible without warrant  

This scenario treats AI use in analysis as **high epistemic risk**, requiring explicit safeguards.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI, teams should clarify:
- the research questions and theoretical commitments  
- what counts as evidence versus interpretation  
- where uncertainty or ambiguity is expected  

Key awareness questions:
- What decisions are we making at this stage?  
- Where might AI outputs overstate confidence?  
- What assumptions are embedded in tools or models?  

AI should be used to surface possibilities, not to decide meaning.

---

### 4.2 Human–AI Co-Agency

In analysis contexts:
- humans remain responsible for interpretation and claims  
- AI may assist with organisation, patterning, or exploration  

Good co-agency means:
- analytic questions are human-defined  
- AI outputs are treated as provisional artefacts  
- interpretive decisions are documented and owned  

Avoid:
- allowing AI to select findings implicitly  
- delegating sensemaking to automated pipelines  

---

### 4.3 Applied Practice

Appropriate AI uses include:
- exploratory analysis to identify areas for deeper review  
- assisting with coding or classification under supervision  
- stress-testing interpretations against alternative framings  

Inappropriate uses include:
- drawing conclusions directly from AI outputs  
- automating interpretation without validation  
- suppressing anomalous data that does not fit patterns  

AI should support methodological reflexivity, not replace it.

---

### 4.4 Ethics, Equity & Impact

Analytical choices have ethical consequences.

Use the Framework to ask:
- Whose data or voices are being amplified or marginalised?  
- Could AI reproduce historical bias or exclusion?  
- Are findings being framed responsibly?  

Ethical analysis requires care in representation and interpretation.

---

### 4.5 Decision-Making & Governance

Good governance practices include:
- transparent documentation of analytic methods  
- versioning of models, prompts, and parameters  
- peer review or audit of AI-assisted analysis  

If AI is used:
- record tools, settings, and assumptions  
- ensure findings are reproducible where possible  
- maintain clear lines of accountability  

This supports credibility and trust.

---

### 4.6 Reflection, Learning & Renewal

After analysis phases, reflect:
- How did AI use influence interpretation?  
- Where did it clarify or obscure understanding?  
- What safeguards should be strengthened?  

Reflection supports epistemic learning and methodological improvement.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What alternative interpretations are plausible?  
- What evidence would challenge our current view?  
- Where might we be over-interpreting patterns?  

**Optional AI prompts**
- “Generate alternative explanations for this pattern, noting limitations.”  
- “Identify data points that do not fit the dominant trend.”  

**Pause & check**
- Are we mistaking correlation for explanation?  
- Is AI narrowing or expanding interpretive space?

---

## 6. After-Action Reflection

Following analysis and interpretation:
- Are claims proportionate to evidence?  
- Have uncertainties been documented?  
- How will interpretations be reviewed or updated?  

Feed insights into dissemination and peer review processes.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- use AI to enhance analytical capacity responsibly  
- avoid epistemic overreach and automation bias  
- strengthen transparency and reproducibility  
- integrate ethics into interpretation  
- build mature AI capability in research analysis contexts  
