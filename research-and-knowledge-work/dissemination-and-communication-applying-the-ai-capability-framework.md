# Dissemination and Communication: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

---

## 1. Purpose of This Scenario

This scenario supports dissemination and communication activities where research findings, insights, or outputs are shared with different audiences. These moments shape public understanding, professional practice, policy influence, and institutional reputation.

AI is increasingly used in dissemination to draft summaries, tailor messages for different audiences, generate visuals, or optimise reach. While these uses can improve accessibility and efficiency, they also risk over-simplification, exaggeration, loss of nuance, or misrepresentation of uncertainty if not carefully governed.

The purpose of this scenario is to help teams use AI to support responsible communication, while ensuring accuracy, proportionality, and trust remain central.

This scenario is designed to support:
- Researchers and authors  
- Communications and engagement teams  
- Policy and knowledge-exchange professionals  
- Leaders responsible for public-facing outputs  

---

## 2. Situation & Context

Dissemination occurs when:
- findings are ready to be shared  
- outputs are adapted for different audiences  
- organisations seek visibility, influence, or impact  

Typical pressures include:
- demand for clarity and simplicity  
- competition for attention  
- incentives to emphasise novelty or certainty  

AI may be proposed to draft summaries, headlines, or audience-specific versions. How it is used will shape whether communication builds trust or undermines credibility.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in dissemination and communication to:
- summarise findings for non-specialist audiences  
- tailor messages for policy, practice, or media  
- generate visuals or explanatory materials  
- optimise language for reach or engagement  

These uses matter because:
- summarisation can remove caveats and uncertainty  
- tailoring may distort emphasis across audiences  
- optimisation can privilege attention over accuracy  

This scenario treats AI use in dissemination as **medium-risk with high reputational impact**.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI, teams should clarify:
- the purpose of the communication  
- the audience’s needs and responsibilities  
- what uncertainty must be retained  

Key awareness questions:
- What must this audience understand — and what should remain qualified?  
- Where could AI outputs oversimplify or overstate?  
- What would responsible communication look like here?  

AI should be used to support understanding, not to manufacture certainty.

---

### 4.2 Human–AI Co-Agency

In dissemination contexts:
- humans remain responsible for accuracy and framing  
- AI may assist with drafting and adaptation  

Good co-agency means:
- authors review and approve all AI-assisted text  
- framing decisions are made deliberately  
- accountability for messaging is explicit  

Avoid:
- publishing AI-generated summaries without validation  
- allowing AI to prioritise engagement over integrity  

---

### 4.3 Applied Practice

Appropriate AI uses include:
- drafting multiple audience-specific versions for review  
- simplifying language while preserving meaning  
- generating explanatory visuals to support comprehension  

Inappropriate uses include:
- exaggerating impact or certainty  
- removing methodological caveats for accessibility  
- automating public communication without oversight  

AI should support clarity with integrity, not hype.

---

### 4.4 Ethics, Equity & Impact

Communication choices shape public perception.

Use the Framework to ask:
- Who might be affected by how this is communicated?  
- Are certain audiences being misled or excluded?  
- Could AI-generated framing amplify harm or misunderstanding?  

Ethical dissemination prioritises care, proportionality, and inclusion.

---

### 4.5 Decision-Making & Governance

Good governance includes:
- clear approval processes for public outputs  
- alignment with institutional communication policies  
- documentation of key messaging decisions  

If AI is used:
- record its role in drafting or adaptation  
- ensure accountability for final messaging  
- avoid opaque content pipelines  

This supports reputational stewardship and trust.

---

### 4.6 Reflection, Learning & Renewal

After dissemination, reflect:
- How was the communication received?  
- Did AI use help or hinder understanding?  
- What should change next time?  

Reflection supports continuous improvement in responsible communication.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What uncertainty are we holding responsibly?  
- Where might this be misunderstood?  
- Would we stand by this framing publicly?  

**Optional AI prompts**
- “Rewrite this summary to retain uncertainty and limitations.”  
- “Generate alternative framings and note their risks.”  

**Pause & check**
- Are we prioritising reach over accuracy?  
- Is AI supporting trust or eroding it?

---

## 6. After-Action Reflection

Following dissemination:
- What feedback did we receive?  
- Were there unintended consequences?  
- How should governance evolve?  

Feed insights into future communication strategies.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- communicate research responsibly using AI  
- avoid exaggeration and misrepresentation  
- adapt messages ethically across audiences  
- protect credibility and public trust  
- build mature AI capability in knowledge exchange contexts  
