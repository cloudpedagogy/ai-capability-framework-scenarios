# Incident Response and AI Use: Applying the AI Capability Framework

## 1. Purpose of This Scenario

This scenario supports incident response situations where organisations must act quickly to manage operational, reputational, safety, or data-related incidents. These moments are characterised by urgency, uncertainty, incomplete information, and heightened accountability.

AI is increasingly introduced during incident response to summarise events, analyse logs, draft updates, predict impacts, or support coordination. While these uses can assist under pressure, they also carry significant risk: false confidence, premature closure, automation bias, and the erosion of human responsibility at precisely the moment it matters most.

The purpose of this scenario is to help teams use AI, if at all, as a **bounded support for situational awareness and coordination**, while ensuring that judgement, escalation decisions, and accountability remain firmly human-led.

This scenario is designed to support:
- Incident response leads and coordinators  
- Senior leaders and executive duty officers  
- Risk, resilience, and business continuity teams  
- IT, data protection, and operational response teams  
- Communications and governance functions involved in incident management  

---

## 2. Situation & Context

An incident has occurred, or is unfolding. Examples include:
- a data breach or cybersecurity incident  
- a system outage or service failure  
- a serious operational or safety incident  
- reputational or regulatory exposure emerging rapidly  

At this point:
- information is partial, evolving, or contradictory  
- pressure exists to act decisively and communicate quickly  
- roles and escalation thresholds may be tested  

AI may be proposed to:
- summarise incident reports or logs  
- generate timelines or situation summaries  
- draft internal updates or holding statements  
- support scenario exploration  

How AI is used — or constrained — will shape whether the response remains controlled, credible, and accountable.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used during incident response to:
- consolidate inputs from multiple sources
- summarise technical or operational data for leaders
- draft updates for internal coordination
- explore potential downstream impacts

These uses matter because:
- summaries can hide uncertainty or disagreement  
- AI-generated narratives can feel authoritative without being verified  
- speed can displace deliberation and escalation discipline  

This scenario treats AI use in incident response as **high-risk and time-sensitive**, requiring explicit boundaries and continuous human oversight.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI in an incident, teams should clarify:
- what is known, unknown, and contested  
- what decisions are required now versus later  
- where uncertainty must be explicitly held  

Key awareness questions:
- Are we using AI to understand the situation, or to feel in control?
- What information is provisional or unverified?
- Where could AI outputs create false certainty?

AI should be used to **surface uncertainty**, not suppress it.

---

### 4.2 Human–AI Co-Agency

In incident response:
- humans remain accountable for decisions and escalation  
- AI may assist with organisation, not authority  

Good co-agency means:
- humans decide what questions AI is allowed to address  
- AI outputs are treated as drafts or working artefacts  
- leadership responsibility is never delegated to tools  

Avoid:
- allowing AI to frame the incident narrative unchallenged  
- treating AI summaries as decision-ready  

---

### 4.3 Applied Practice

Appropriate AI uses include:
- compiling timelines from verified inputs  
- summarising agreed facts for coordination  
- supporting note-taking or information organisation  

Inappropriate uses include:
- recommending response actions or priorities  
- predicting outcomes without sufficient evidence  
- drafting external communications without review  

AI should support **coordination under pressure**, not decision substitution.

---

### 4.4 Ethics, Equity & Impact

Incidents often have uneven impact.
Use the Framework to ask:
- Who is affected immediately and indirectly?
- Could AI use obscure harm to less visible groups?
- Are we prioritising speed over care or accuracy?

Ethical incident response requires attention to harm, not just resolution.

---

### 4.5 Decision-Making & Governance

Strong governance during incidents includes:
- clear escalation thresholds and authority lines  
- disciplined separation of facts, assumptions, and decisions  
- documented rationale for key actions  

If AI is used:
- record where and how it informed understanding  
- ensure human sign-off on all decisions and communications  
- avoid creating opaque or unverifiable decision trails  

This supports post-incident accountability and review.

---

### 4.6 Reflection, Learning & Renewal

After the immediate response, reflect:
- Where did AI help clarify the situation?
- Where did it risk narrowing judgement?
- What boundaries should be strengthened next time?

Reflection supports organisational learning and future resilience.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What do we know for certain right now?
