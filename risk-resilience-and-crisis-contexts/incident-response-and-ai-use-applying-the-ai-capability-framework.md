# Incident Response and AI Use: Applying the AI Capability Framework

Framework: CloudPedagogy AI Capability Framework (2026 Edition)  
Licence: CC BY-NC-SA 4.0

## 1. Purpose of This Scenario

This scenario supports incident response situations where organisations must act quickly to manage operational, reputational, safety, or data-related incidents. These moments are characterised by urgency, uncertainty, incomplete information, and heightened accountability.

AI is increasingly introduced during incident response to summarise events, analyse logs, draft updates, predict impacts, or support coordination. While these uses can assist under pressure, they also carry significant risk: false confidence, premature closure, automation bias, and erosion of human responsibility at precisely the moment it matters most.

The purpose of this scenario is to help teams use AI, if at all, as a **bounded support for situational awareness and coordination**, while ensuring that judgement, escalation decisions, and accountability remain firmly human-led.

This scenario is designed to support:
- Incident response leads and coordinators
- Senior leaders and executive duty officers
- Risk, resilience, and business continuity teams
- IT, data protection, and operational response teams
- Communications and governance functions involved in incident management

---

## 2. Situation & Context

An incident has occurred or is unfolding. Examples include:
- a data breach or cybersecurity incident
- a system outage or service failure
- a serious operational or safety incident
- reputational or regulatory exposure emerging rapidly

At this stage:
- information is partial, evolving, or contradictory
- pressure exists to act decisively and communicate quickly
- escalation thresholds and role clarity may be tested
- emotional and reputational stakes are high

AI may be proposed to:
- summarise incident reports or technical logs
- generate timelines or situation summaries
- draft internal updates or holding statements
- explore possible downstream impacts or scenarios

How AI is used — or deliberately constrained — will shape whether the response remains controlled, credible, and defensible.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used during incident response to:
- consolidate inputs from multiple teams or systems
- summarise technical detail for non-specialist leaders
- draft internal coordination updates
- support exploratory scenario thinking

These uses matter because:
- summaries can hide uncertainty, disagreement, or gaps
- AI-generated narratives can sound authoritative without verification
- speed can displace escalation discipline and reflective judgement
- early framing can anchor subsequent decisions incorrectly

This scenario treats AI use in incident response as **high-risk and time-sensitive**, requiring explicit boundaries and continuous human oversight.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI during an incident, teams should clarify:
- what is known, unknown, and actively contested
- what decisions are required immediately versus later
- where uncertainty must be explicitly retained

Key awareness questions:
- Are we using AI to understand the situation, or to feel in control?
- What information is provisional or unverified?
- Where could AI outputs create false certainty or premature closure?

AI should be used to **surface uncertainty**, not suppress it.

---

### 4.2 Human–AI Co-Agency

In incident response:
- humans remain fully accountable for decisions and escalation
- AI may assist with organisation and sensemaking, not authority

Good co-agency means:
- humans define what questions AI is permitted to address
- AI outputs are treated as working artefacts, not conclusions
- leadership responsibility is explicit and non-transferable

Avoid:
- allowing AI to frame the incident narrative unchallenged
- treating AI summaries as decision-ready
- substituting AI confidence for human accountability

---

### 4.3 Applied Practice

Appropriate AI uses include:
- compiling timelines from verified inputs
- organising incident notes across teams
- summarising agreed facts for coordination purposes

Inappropriate uses include:
- recommending response actions or priorities
- predicting outcomes without sufficient evidence
- drafting external communications without senior review

AI should support **coordination under pressure**, not decision substitution.

---

### 4.4 Ethics, Equity & Impact

Incidents often have uneven or hidden impacts.

Use the Framework to ask:
- Who is affected immediately and indirectly?
- Could AI use obscure harm to less visible groups?
- Are we prioritising speed over care, accuracy, or fairness?

Ethical incident response requires attention to harm, not just resolution.

---

### 4.5 Decision-Making & Governance

Strong governance during incidents includes:
- clear escalation thresholds and authority lines
- disciplined separation of facts, assumptions, and decisions
- explicit documentation of key judgements and trade-offs

If AI is used:
- record where and how it informed understanding
- ensure human sign-off on all decisions and communications
- avoid creating opaque or unverifiable decision trails

This supports post-incident accountability, audit, and learning.

---

### 4.6 Reflection, Learning & Renewal

After the immediate response, reflect:
- Where did AI help clarify the situation?
- Where did it risk narrowing judgement?
- Which boundaries should be strengthened next time?

Reflection supports organisational learning and future resilience rather than blame.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What do we know for certain right now?
- What assumptions are we making under pressure?
- What would justify escalation or pause?

**Optional AI prompts**
- “Summarise verified facts separately from assumptions or hypotheses.”
- “List uncertainties or information gaps explicitly.”

**Pause & check**
- Are we mistaking speed for control?
- Would we defend this decision pathway later?

---

## 6. After-Action Reflection

Following the incident:
- Did AI use support or distort situational awareness?
- Were escalation and accountability clear throughout?
- What documentation or governance gaps were revealed?

Capture learning to strengthen future incident preparedness and AI boundaries.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- respond to incidents without surrendering judgement to AI
- maintain accountability under pressure
- avoid false certainty and automation bias
- strengthen governance and escalation discipline
- build resilient, human-centred AI capability in crisis contexts
