# Reputational Risk Assessment: Applying the AI Capability Framework

Framework: CloudPedagogy AI Capability Framework (2026 Edition)  
Licence: CC BY-NC-SA 4.0

## 1. Purpose of This Scenario

This scenario supports reputational risk assessment contexts where organisations must evaluate how actions, decisions, or incidents may affect trust, legitimacy, credibility, and public confidence.

AI is increasingly introduced into reputational risk work to scan sentiment, analyse media coverage, model potential reactions, benchmark comparable incidents, or generate risk narratives for leaders. While these uses can surface patterns and broaden awareness, they also risk amplifying noise, mistaking correlation for insight, and framing reputational risk as something that can be optimised or predicted rather than judiciously assessed.

The purpose of this scenario is to help teams use AI, if at all, as a **sensemaking support**, while ensuring that ethical judgement, contextual understanding, and accountability for reputational decisions remain firmly human-led.

This scenario is designed to support:
- Senior leaders and executive teams  
- Risk, compliance, and assurance functions  
- Communications and public affairs teams  
- Policy, legal, and governance professionals  
- Boards and committees overseeing organisational reputation  

---

## 2. Situation & Context

An organisation is assessing reputational risk in relation to:
- a developing incident or crisis  
- a proposed decision, policy, or initiative  
- public-facing AI use or automation  
- emerging scrutiny from media, regulators, or stakeholders  

At this point:
- impacts are often indirect, delayed, or contested  
- reputational harm may be uneven across groups  
- pressure exists to anticipate reaction and reassure leadership  

AI may be proposed to:
- analyse media or social sentiment  
- identify similar historical cases  
- generate risk summaries or likelihood estimates  
- support briefing papers for decision-makers  

How AI is used will shape whether reputational risk is understood thoughtfully — or reduced to misleading metrics.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in reputational risk assessment to:
- scan large volumes of commentary or reporting  
- identify emerging themes or narratives  
- benchmark organisational exposure against peers  
- generate structured risk summaries  

These uses matter because:
- sentiment analysis can flatten nuance and disagreement  
- visibility does not equal importance or harm  
- algorithmic weighting can privilege louder voices  
- generated narratives may appear authoritative without accountability  

This scenario treats AI use in reputational risk assessment as **medium- to high-risk**, particularly when outputs influence strategic or public decisions.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI for reputational risk, teams should clarify:
- what type of reputation is at stake (trust, legitimacy, credibility)
- whose perspectives matter most in this context
- what harms are plausible versus speculative

Key awareness questions:
- Are we confusing attention with impact?
- What reputational risks cannot be quantified?
- Where might AI exaggerate or underplay concern?

AI should be used to **broaden awareness**, not to close judgement prematurely.

---

### 4.2 Human–AI Co-Agency

In reputational assessment:
- humans remain responsible for interpretation and judgement  
- AI may assist with pattern surfacing, not evaluation  

Good co-agency means:
- humans frame what “reputation” means in context  
- AI outputs are interrogated, not accepted  
- final risk judgements are explicitly human-authored  

Avoid:
- deferring to AI-generated risk scores  
- treating sentiment trends as decision drivers  
- outsourcing ethical interpretation to tools  

---

### 4.3 Applied Practice

Appropriate AI uses include:
- identifying a range of possible stakeholder reactions  
- surfacing blind spots or overlooked audiences  
- supporting comparative analysis for discussion  

Inappropriate uses include:
- ranking reputational risk without context  
- predicting public reaction with false precision  
- using AI outputs to justify pre-made decisions  

AI should support **deliberation**, not reputational determinism.

---

### 4.4 Ethics, Equity & Impact

Reputation is linked to power and voice.

Use the Framework to ask:
- Whose reputational harm is being prioritised?
- Are marginalised groups being overlooked?
- Could AI analysis reinforce dominant narratives?

Ethical reputational assessment requires care, humility, and inclusion.

---

### 4.5 Decision-Making & Governance

Strong governance of reputational risk includes:
- clear ownership of reputational judgements  
- separation between analysis and decision authority  
- documented rationales for risk tolerance decisions  

If AI is used:
- record its role and limitations explicitly  
- avoid treating AI outputs as evidence of “due diligence”  
- ensure decisions remain contestable and reviewable  

This supports defensibility under scrutiny.

---

### 4.6 Reflection, Learning & Renewal

After reputational decisions are made, reflect:
- Did AI use clarify or distort understanding?
- Were any perspectives missing or underweighted?
- How should future assessments evolve?

Reflection strengthens organisational judgement over time.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What reputational harm are we most concerned about — and why?
- Whose trust matters most in this situation?
- What cannot be captured by data alone?

**Optional AI prompts**
- “Identify stakeholder groups that may be overlooked.”
- “Summarise competing narratives without ranking them.”

**Pause & check**
- Are we using AI to think more carefully, or to feel reassured?
- Would we defend this assessment publicly?

---

## 6. After-Action Reflection

Following reputational risk decisions:
- How did actual reactions compare with expectations?
- Did AI analysis add value or noise?
- What governance lessons emerged?

Feed insights into future risk and assurance processes.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- assess reputational risk with greater judgement and care
- avoid false certainty driven by AI metrics
- surface ethical and equity considerations
- strengthen governance around AI-informed risk work
- build mature, reflective reputational capability
