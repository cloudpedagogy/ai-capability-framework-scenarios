# Academic Advising Conversations: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0  

---

## 1. Purpose of This Scenario

This scenario supports academic advising conversations where staff and students discuss progression, choices, challenges, and next steps in learning. These interactions are relational, trust-based, and judgement-heavy. They often combine academic guidance, pastoral awareness, and institutional responsibility.

AI is increasingly present in advising contexts — sometimes explicitly through institutional systems, sometimes informally through student use or staff experimentation. AI may be used to summarise records, suggest pathways, surface risks, or generate guidance language. While these uses can support preparation and consistency, they also introduce risks of depersonalisation, misinterpretation, inappropriate advice, or boundary drift.

The purpose of this scenario is to help advisors use AI, if at all, as a **background support**, while ensuring that responsibility, care, and judgement remain explicitly human.

This scenario is designed to support:
- Academic advisors and personal tutors  
- Programme and year leads  
- Student success and retention teams  
- Professional services staff involved in advising  

---

## 2. Situation & Context

An academic advising conversation is scheduled with a student. The meeting may be routine or triggered by concern. Common contexts include:

- discussion of academic progress or performance  
- choices about modules, pathways, or progression  
- balancing study with work, health, or personal pressures  
- early signals of disengagement or difficulty  

The advisor may have access to:
- student records or dashboards  
- notes from previous meetings  
- institutional guidance or progression rules  

AI may be proposed or already embedded to:
- summarise student records or prior notes  
- flag “at-risk” indicators  
- suggest talking points or next steps  
- draft follow-up communications  

How AI is used — or deliberately *not* used — will shape trust, agency, and the quality of support provided.

---

## 3. Where AI Might Be Used (and Why That Matters)

In academic advising, AI may be used to:

- summarise academic history or engagement data  
- surface patterns or risk indicators  
- suggest programme or module options  
- draft advising notes or follow-up emails  

These uses matter because:

- summaries can flatten complexity or context  
- risk flags may overstate certainty  
- recommendations can appear authoritative  
- automated language can reduce relational sensitivity  

This scenario treats AI use in advising as **medium- to high-risk**, depending on student vulnerability and decision stakes.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI in advising, clarify:

- the purpose of this conversation (support, decision, exploration)  
- the student’s current context and agency  
- what information is relevant versus intrusive  

Key awareness questions:
- Is this a routine academic check-in or a care-adjacent conversation?
- What uncertainty or ambiguity needs space to surface?
- Could AI framing pre-shape how the student is perceived?

AI should not be used to *define* the student’s situation before hearing them.

---

### 4.2 Human–AI Co-Agency

In advising conversations:

- humans remain responsible for judgement, care, and decisions  
- AI may assist with preparation or documentation only  

Good co-agency means:
- the advisor controls when and how AI is used  
- AI outputs are treated as tentative and revisable  
- the student is not positioned as a data profile  

Avoid:
- allowing AI-generated risk labels to steer the conversation  
- deferring difficult judgement to automated indicators  

---

### 4.3 Applied Practice

Appropriate AI uses include:
- preparing a neutral summary of academic records  
- listing possible options for discussion (not recommendation)  
- drafting follow-up notes for human review  

Inappropriate uses include:
- generating advice without contextual understanding  
- predicting student outcomes or behaviour  
- scripting conversations or responses  

AI should support *preparedness*, not replace relational engagement.

---

### 4.4 Ethics, Equity & Impact

Advising decisions have equity implications.

Use the Framework to ask:
- Are certain students more likely to be flagged or categorised?
- Could AI outputs reinforce deficit narratives?
- Is the student’s voice genuinely centred?

Ethical advising prioritises dignity, agency, and trust over efficiency.

---

### 4.5 Decision-Making & Governance

Good governance in advising includes:
- clarity about what decisions advisors can and cannot make  
- appropriate documentation of advice and outcomes  
- alignment with institutional support and escalation pathways  

If AI is used:
- its role should be documented where appropriate  
- final decisions must be human-authored  
- sensitive data should be handled conservatively  

This ensures defensibility and accountability.

---

### 4.6 Reflection, Learning & Renewal

After advising conversations, reflect:
- Did AI use help or hinder the interaction?
- Were assumptions challenged or reinforced?
- What should change next time?

Reflection strengthens advising practice and institutional learning.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- Am I listening more than I am interpreting?
- What does this student need right now?
- Where is judgement required rather than guidance?

**Optional AI prompts**
- “Summarise factual academic information without interpretation.”
- “List institutional options without recommendation.”

**Pause & check**
- Would the student recognise this as fair and supportive?
- Is AI helping me prepare — or pre-judge?

---

## 6. After-Action Reflection

Following the advising interaction:
- Were responsibilities and next steps clear?
- Did the student retain agency?
- Where might AI use need tighter boundaries?

Capture learning to improve future advising conversations.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- support advising with care and judgement  
- avoid data-driven overreach in student support  
- maintain trust in AI-aware advising practices  
- align advising with ethical and governance standards  
- build mature, human-centred AI capability in student support
