# Personal Tutoring and Progress Review: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0  

---

## 1. Purpose of This Scenario

This scenario supports personal tutoring and progress review conversations where an educator and a student reflect on academic development, engagement, and future direction over time. These interactions are longitudinal rather than transactional, and they often blend academic judgement with care, encouragement, and institutional responsibility.

AI is increasingly introduced into progress review contexts through dashboards, engagement analytics, early-alert systems, and automated summaries. While these tools can surface useful signals, they also risk narrowing attention to proxy metrics, creating deficit narratives, or shifting responsibility for judgement away from the tutor.

The purpose of this scenario is to help tutors use AI, if at all, as a **secondary sensemaking aid**, while ensuring that interpretation, support, and decisions remain grounded in human judgement and relationship.

This scenario is designed to support:
- Personal tutors and academic mentors  
- Programme and year leads  
- Student success and retention teams  
- Professional services staff supporting progress monitoring  

---

## 2. Situation & Context

A progress review is scheduled as part of an ongoing tutoring relationship. The review may be:

- routine and scheduled  
- triggered by assessment results or engagement data  
- part of probation, support, or progression processes  

The tutor may have access to:
- assessment outcomes across modules  
- attendance or engagement dashboards  
- notes from previous reviews  
- flags generated by institutional systems  

AI may be used to:
- summarise progress trends over time  
- identify patterns or anomalies  
- highlight students meeting predefined “risk” thresholds  
- draft progress review notes  

How these tools are used will shape whether the review feels supportive and developmental or evaluative and surveillance-driven.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in progress review contexts to:

- aggregate assessment and engagement data  
- visualise trends across time or cohorts  
- generate alerts or categorisations  
- standardise review documentation  

These uses matter because:

- trends can obscure contextual causes  
- engagement metrics are imperfect proxies for learning  
- automated flags may carry implicit judgement  
- standardisation can reduce responsiveness to individual context  

This scenario treats AI use in progress review as **medium-risk**, with higher risk where reviews influence progression, funding, or disciplinary outcomes.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI in progress reviews, clarify:

- the purpose of the review (support, check-in, decision)  
- what data does and does not represent  
- how much weight metrics should carry  

Key awareness questions:
- Are we reviewing learning, engagement, or compliance?
- What assumptions are embedded in the indicators we see?
- What information can only emerge through conversation?

AI should be used to prompt inquiry, not to define success or failure.

---

### 4.2 Human–AI Co-Agency

In progress review contexts:

- tutors remain responsible for interpretation and support  
- AI may assist with aggregation and recall  

Good co-agency means:
- tutors contextualise all AI-generated signals  
- students are invited to interpret data with the tutor  
- decisions are not automated or implied by dashboards  

Avoid:
- treating AI indicators as objective truth  
- positioning the tutor as an enforcer of metrics  

---

### 4.3 Applied Practice

Appropriate AI uses include:
- preparing neutral summaries of progress data  
- identifying areas for discussion, not diagnosis  
- supporting consistent documentation  

Inappropriate uses include:
- predicting student outcomes or likelihood of failure  
- ranking students by “risk” without context  
- replacing dialogue with data review  

AI should support reflective conversation, not replace it.

---

### 4.4 Ethics, Equity & Impact

Progress monitoring has equity implications.

Use the Framework to ask:
- Are certain students disproportionately flagged?
- Do metrics disadvantage non-traditional learners?
- Are we reinforcing deficit narratives?

Ethical progress review requires sensitivity to diversity of circumstance and learning pathways.

---

### 4.5 Decision-Making & Governance

Good governance practices include:
- clarity about what actions follow progress reviews  
- transparency about how data is used  
- appropriate separation between support and sanction  

If AI is used:
- its role should be explainable to students  
- human validation must precede decisions  
- records should be proportionate and secure  

This supports trust and institutional defensibility.

---

### 4.6 Reflection, Learning & Renewal

After progress reviews, reflect:
- Did AI use deepen understanding or narrow it?
- Were students empowered to interpret their own progress?
- What indicators should be questioned or refined?

Reflection supports improvement of both tutoring practice and monitoring systems.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What story might this data be telling — and what might it miss?
- How is the student making sense of their progress?
- Where do I need to exercise judgement rather than explanation?

**Optional AI prompts**
- “Summarise progress indicators without evaluative language.”
- “Highlight changes over time without ranking or prediction.”

**Pause & check**
- Does this review feel supportive rather than surveillant?
- Are we discussing learning, not just metrics?

---

## 6. After-Action Reflection

Following the review:
- Were expectations and next steps clear?
- Did the student retain agency and voice?
- Did AI use require recalibration?

Capture insights to refine future progress review processes.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- conduct progress reviews with care and integrity  
- avoid metric-driven overreach  
- support diverse learning trajectories  
- maintain trust in data-informed tutoring  
- build reflective, human-centred AI capability in student support
