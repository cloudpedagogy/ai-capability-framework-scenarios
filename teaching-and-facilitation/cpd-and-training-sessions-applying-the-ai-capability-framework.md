# CPD and Training Sessions: Applying the AI Capability Framework

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

---

## 1. Purpose of This Scenario

This scenario supports continuing professional development (CPD) and training sessions where staff, educators, and professionals develop new capabilities, particularly in relation to AI, digital practice, and evolving professional roles.

AI is increasingly introduced into CPD to personalise learning, generate examples, support practice activities, or summarise content. While these uses can enhance engagement and efficiency, they also risk over-scaffolding learning, reducing critical reflection, or positioning AI as an expert instructor rather than a learning partner.

The purpose of this scenario is to help facilitators use AI to support genuine capability development, while ensuring that learning remains reflective, contextual, and grounded in human judgement.

This scenario is designed to support:
- CPD facilitators and trainers  
- Educational developers and learning designers  
- Professional services leads  
- Academic staff involved in staff development  

---

## 2. Situation & Context

A CPD or training session is convened to:
- build skills or understanding in a specific area  
- support professional transition or upskilling  
- introduce new tools, policies, or practices  

These sessions often involve:
- participants with diverse prior experience  
- varying confidence with technology or AI  
- pressure to demonstrate immediate relevance and value  

AI may be used to generate examples, tailor activities, or support reflection. How it is used will shape whether learning is shallow and performative or deep and transferable.

---

## 3. Where AI Might Be Used (and Why That Matters)

AI may be used in CPD and training sessions to:
- generate case studies or scenarios  
- support practice exercises or simulations  
- personalise prompts or reflective questions  
- summarise concepts or discussions  

These uses matter because:
- generated examples may lack contextual relevance  
- personalised feedback can mask assumptions or bias  
- summaries may discourage participant sensemaking  

This scenario treats AI use in CPD as **medium-risk with high pedagogical influence**, requiring thoughtful facilitation.

---

## 4. Applying the AI Capability Framework

### 4.1 Awareness

Before using AI, facilitators should clarify:
- the intended learning outcomes  
- what participants need to think through themselves  
- where struggle and uncertainty are pedagogically valuable  

Key awareness questions:
- What capability are we actually trying to develop?  
- Where should participants exercise judgement?  
- What might AI make too easy?  

AI should be used to support learning, not to bypass it.

---

### 4.2 Human–AI Co-Agency

In CPD contexts:
- humans remain responsible for learning design and facilitation  
- AI may assist with examples, prompts, or scaffolding  

Good co-agency means:
- facilitators frame how AI is used in activities  
- participants are encouraged to critique AI outputs  
- learning remains dialogic and reflective  

Avoid:
- presenting AI as the authoritative instructor  
- outsourcing explanation or feedback entirely to tools  

---

### 4.3 Applied Practice

Appropriate AI uses include:
- generating contrasting examples for analysis  
- supporting role-play or scenario exploration  
- prompting reflective questions for discussion  

Inappropriate uses include:
- providing ready-made answers to learning tasks  
- automating assessment or evaluation of learning  
- replacing facilitator interaction with AI responses  

AI should support practice and reflection, not completion.

---

### 4.4 Ethics, Equity & Impact

CPD and training shape professional norms and confidence.

Use the Framework to ask:
- Are all participants equally supported by AI use?  
- Does AI privilege certain learning styles or backgrounds?  
- Are ethical implications of AI practice being surfaced?  

Ethical CPD promotes critical literacy and inclusive participation.

---

### 4.5 Decision-Making & Governance

Good governance in CPD includes:
- clarity about appropriate AI use in learning contexts  
- transparency about data use and privacy  
- alignment with institutional policies and values  

If AI is used:
- communicate boundaries clearly to participants  
- avoid collecting unnecessary personal data  
- ensure facilitators remain accountable for learning quality  

This supports trust and responsible practice.

---

### 4.6 Reflection, Learning & Renewal

After training sessions, reflect:
- Did AI use enhance or inhibit learning?  
- Where did participants struggle productively?  
- How should future sessions evolve?  

Reflection supports continuous improvement in capability development.

---

## 5. In-the-Moment Prompts & Checks

**Human reflection prompts**
- What are participants learning to do, not just know?  
- Where is critical judgement being exercised?  
- Are we modelling responsible AI use?  

**Optional AI prompts**
- “Generate two contrasting examples that illustrate different approaches to this problem.”  
- “Pose reflective questions that encourage participants to critique this output.”  

**Pause & check**
- Is AI supporting learning or performing it for participants?  
- Would learning be deeper if we slowed down?

---

## 6. After-Action Reflection

Following CPD sessions:
- What capabilities have visibly strengthened?  
- How did participants respond to AI-supported activities?  
- What adjustments are needed next time?  

Use insights to refine training design and facilitation.

---

## 7. What This Scenario Delivers

This scenario helps organisations:
- design CPD that builds genuine AI capability  
- avoid superficial or tool-centric training  
- support reflective and ethical professional learning  
- strengthen facilitator confidence with AI  
- embed the AI Capability Framework into everyday development practice  
